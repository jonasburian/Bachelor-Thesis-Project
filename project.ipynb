{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd2b25d5",
   "metadata": {},
   "source": [
    "# Thesis Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "157ff5a7",
   "metadata": {},
   "source": [
    "## Requirements and Imports\n",
    "\n",
    "All requirements in this project are managed by `Pipenv` and are denoted in the `Pipfile`, which can be found in the same directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1b4b0800",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic imports\n",
    "import os\n",
    "import re\n",
    "import math\n",
    "import glob\n",
    "import wfdb\n",
    "import time\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from functools import partial\n",
    "\n",
    "# PyTorch related imports\n",
    "import torch\n",
    "import torchinfo\n",
    "import torch.nn as nn\n",
    "import torch.jit as jit\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# RayTune related imports\n",
    "from ray import tune, put, get\n",
    "from ray.tune import CLIReporter\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "\n",
    "# Sklearn and Scipy related imports\n",
    "from scipy import signal\n",
    "from statsmodels.tsa.stattools import ccf\n",
    "from skimage.restoration import denoise_wavelet\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e8cb7b9",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "This the following code cell can be used to configure certain aspects of the experiment.\n",
    "To specify offsets (for instance for the sampling rate or the segment size), please refer to the official [pandas documentation](https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#offset-aliases)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c145768a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a random seed for pytorch (always split the data the same way), for the random package and for numpy. Required for reproducability.\n",
    "random.seed(1658497162847124986)\n",
    "torch.manual_seed(1658497162847124986)\n",
    "np.random.seed(1658497162)\n",
    "\n",
    "# If a GPU (Cuda) is available, it will be used to train and test the machine learning models.\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# The directory for saving and loading the trained models.\n",
    "model_directory = './models/'\n",
    "\n",
    "# Here, some basic settings for the datasets and are set.\n",
    "data_directory = './data/'\n",
    "sampling_rate = '10L' # 10ms, The signal will be resampled based on this sampling rate.\n",
    "segment_size = '10240L' # 10240 ms, The signal will be split based on this length.\n",
    "segment_size_samples = int(pd.to_timedelta(segment_size).total_seconds() / pd.to_timedelta(sampling_rate).total_seconds())\n",
    "train_split = 0.8\n",
    "\n",
    "# The target noise SNR values for training and testing.\n",
    "train_target_snr_dbs = [-1.5, 0, 1.5, 3.5, 5, 6.5] # dB\n",
    "test_target_snr_dbs =  [-1, 0, 0.5, 1, 3, 5, 8] # dB\n",
    "\n",
    "# Number of epochs for training.\n",
    "num_epochs = 256"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fbeb9e6",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "This is a utilitarian class which is used for managing the required data. It inherits from the PyTorch `Dataset` class, which provides tools like splitting the data into train and test subsets or using it in dataloaders to efficiently access the data. The dataset for this experiment coprises the CEBS dataset and another dataset, called D2. The data from the denoted datasets will be loaded directly when initialising an object of the class. Each dataset will be imported, depending on its specific characteristics, the schemas will be normalized, the two dataset will be resampled and each dataset will be grouped according to `segment_size_samples`. Subsequelty, the two datasets will be combined. Initially, no noise will be added to the data, i.e. the clean and noisy data will be the same in the beginning. This is done so that training and testing can be done with different noise levels. The noise generated is gaussian white noise. However, this can be substituted with some other noise generation mechanism later, when required. Please note that the code for generating the noise was adopted from [this](https://stackoverflow.com/a/53688043) example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "46e9a7aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(data):\n",
    "    data_concat = np.concatenate(data)\n",
    "    min_val = np.min(data_concat)\n",
    "    max_val = np.max(data_concat)\n",
    "    data_norm = 2 * (data - min_val) / (max_val - min_val) - 1\n",
    "    return data_norm, min_val, max_val\n",
    "\n",
    "def normalize2(clean, noise):\n",
    "    x_concat = np.concatenate((clean, noise))\n",
    "    min_val = np.min(x_concat)\n",
    "    max_val = np.max(x_concat)\n",
    "    y_clean = 2 * (clean-min_val) / (max_val - min_val) - 1\n",
    "    y_noise = 2 * (noise-min_val) / (max_val - min_val) - 1\n",
    "    return y_clean, y_noise, min_val, max_val\n",
    "\n",
    "def denormalize(data, min_val, max_val):\n",
    "    data_denorm = (max_val * data + max_val - data * min_val + min_val) / 2\n",
    "    return data_denorm\n",
    "\n",
    "def bandpass(input_signal):\n",
    "    # https://www.youtube.com/watch?v=juYqcck_GfU\n",
    "    fs = 100.0 # frequency space\n",
    "    lowcut = 5.0 # Hz\n",
    "    highcut = 30.0 # Hz\n",
    "\n",
    "    nyq = 0.5 * fs\n",
    "    low = lowcut / nyq\n",
    "    high = highcut / nyq\n",
    "\n",
    "    order = 4\n",
    "\n",
    "    b, a, = signal.butter(order, [low, high], 'bandpass', analog=False)\n",
    "    y = signal.filtfilt(b, a, input_signal, axis=0)\n",
    "\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c9c8d52a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SCGData(Dataset):\n",
    "\n",
    "    def __init__(self, directory=None, datasets=None, transform=None, ecg=False):\n",
    "\n",
    "        self.directory = directory\n",
    "        self.datasets = datasets\n",
    "        self.transform = transform\n",
    "        self.min_val = None\n",
    "        self.max_val = None\n",
    "        self.ecg = ecg\n",
    "\n",
    "        data = self.__load_datasets()\n",
    "\n",
    "        # data = data.apply(lambda x: bandpass(x))\n",
    "        # data = pd.DataFrame({'clean': data, 'noise': data})\n",
    "        \n",
    "        if self.ecg:\n",
    "            self.x_data = data.SCG.values\n",
    "            self.y_data = data.ECG.values\n",
    "        else:\n",
    "            self.x_data = data.SCG.values\n",
    "            self.y_data = data.SCG.values\n",
    "\n",
    "        self.n_samples = data.shape[0]\n",
    "\n",
    "\n",
    "    def add_noise(self, target_snr_dbs):\n",
    "\n",
    "        if not self.ecg:\n",
    "            data_noise = np.array([self.__add_gaussian(inputs, target_snr_dbs) for inputs in self.y_data])\n",
    "            self.x_data, self.min_val, self.max_val = normalize(data_noise)\n",
    "\n",
    "\n",
    "    def __add_gaussian(self, data, target_snr_dbs):\n",
    "\n",
    "        # target_snr_db = random.choices(target_snr_dbs, weights=target_snr_weights, k=1)[0]\n",
    "        target_snr_db = random.choice(target_snr_dbs)\n",
    "        # target_snr_db = random.uniform(-1, 20) # sample from bigger range provides better results?\n",
    "        # target_snr_db = 1\n",
    "\n",
    "        data_watts = data ** 2\n",
    "        data_avg_watts = np.mean(data_watts)\n",
    "        data_avg_db = 10 * np.log10(data_avg_watts)\n",
    "\n",
    "        noise_avg_db = data_avg_db - target_snr_db\n",
    "        noise_avg_watts = 10 ** (noise_avg_db / 10)\n",
    "\n",
    "        mean_noise = 0\n",
    "        noise = np.random.normal(mean_noise, np.sqrt(noise_avg_watts), len(data_watts))\n",
    "\n",
    "        data_noisy = data + noise\n",
    "        return data_noisy\n",
    "\n",
    "\n",
    "    # Function to import the CEBS dataset\n",
    "    def __load_cebs(self, filename):\n",
    "        \n",
    "        # Using WFDB to import the files.\n",
    "        record = wfdb.rdsamp(filename)\n",
    "        data = record[0]\n",
    "        metadata = record[1]\n",
    "\n",
    "        frequency = metadata['fs']\n",
    "        column_names = metadata['sig_name']\n",
    "        length = metadata['sig_len']\n",
    "\n",
    "        data = pd.DataFrame(data, columns=column_names)\n",
    "        data.drop(['II', 'RESP'], axis=1, inplace=True)\n",
    "        data.rename(columns={'I': 'ECG'}, inplace=True)\n",
    "\n",
    "        # Create a datetime index, as it is not given in the dataset. Required for resampling and splitting the data.\n",
    "        frequency_string = str(int(1/frequency*1000000)) + 'U'\n",
    "        index = pd.date_range(start='1/1/1970', periods=length, freq=frequency_string)\n",
    "        data.set_index(index, inplace=True)\n",
    "\n",
    "        # Resample the data into the desired sampling rate.\n",
    "        data = data.resample(sampling_rate).mean()\n",
    "\n",
    "        # Split the data into groups with segment_size_samples samples.\n",
    "        data = pd.DataFrame([[x.ECG.to_numpy(), x.SCG.to_numpy()] for x in data.rolling(window=1024, step=128) if x.shape[0] == 1024 and not np.isnan(x.SCG).any() and not np.isnan(x.ECG).any()])\n",
    "        data.columns = ['ECG', 'SCG']\n",
    "\n",
    "        data['SCG'], _, _ = normalize(data['SCG'])\n",
    "        data['ECG'], _, _ = normalize(data['ECG'])\n",
    "        \n",
    "        return data\n",
    "\n",
    "\n",
    "    # Function to import the D2 dataset\n",
    "    def __load_d2(self, filename):\n",
    "\n",
    "        # Since the files are not structured the same, they have to be imported differently. The following code does that.\n",
    "        # Regex to identify files with specific names, as they are structured differently.\n",
    "        regex_up_1 = re.compile(r'./data/D2/UP-(((0|1)[0-9])|(20|21))-*') # Files named UP-[01-21]-Raw.csv\n",
    "        regex_up_2 = re.compile(r'./data/D2/UP-(22|23)-*') # Files named UP-[22-23]-Raw.csv\n",
    "\n",
    "        # Import and normalize the structures of the different files.\n",
    "        if re.match(r'./data/D2/CP-*', filename):\n",
    "            data = pd.read_csv(filename, \n",
    "                    sep=',', \n",
    "                    header=1, \n",
    "                    skiprows=[2],\n",
    "                    usecols=['Shimmer_D0CD_Timestamp_Shimmer_CAL', 'Shimmer_D0CD_ECG_LA-RA_24BIT_CAL', 'Shimmer_D0CD_Accel_LN_Z_CAL'], \n",
    "                    dtype={'Shimmer_D0CD_Timestamp_Shimmer_CAL': 'float', 'Shimmer_D0CD_ECG_LA-RA_24BIT_CAL': 'float', 'Shimmer_D0CD_Accel_LN_Z_CAL': 'float'})\n",
    "            data.rename(columns={'Shimmer_D0CD_Timestamp_Shimmer_CAL': 'index', 'Shimmer_D0CD_ECG_LA-RA_24BIT_CAL': 'ECG', 'Shimmer_D0CD_Accel_LN_Z_CAL': 'SCG'}, inplace=True)\n",
    "        elif regex_up_1.match(filename):\n",
    "            data = pd.read_csv(filename, \n",
    "                    sep='\t', \n",
    "                    header=1, \n",
    "                    skiprows=[2],\n",
    "                    usecols=['ECG_TimestampSync_Unix_CAL', 'ECG_ECG_LA-RA_24BIT_CAL', 'ECG_Accel_LN_Z_CAL'], \n",
    "                    dtype={'ECG_TimestampSync_Unix_CAL': 'float', 'ECG_ECG_LA-RA_24BIT_CAL': 'float', 'ECG_Accel_LN_Z_CAL': 'float'})\n",
    "            data.rename(columns={'ECG_TimestampSync_Unix_CAL': 'index', 'ECG_ECG_LA-RA_24BIT_CAL': 'ECG', 'ECG_Accel_LN_Z_CAL': 'SCG'}, inplace=True)\n",
    "        elif regex_up_2.match(filename):\n",
    "            data = pd.read_csv(filename, \n",
    "                    sep=',', \n",
    "                    header=1, \n",
    "                    skiprows=[2],\n",
    "                    usecols=['ECG_Timestamp_Unix_CAL', 'ECG_ECG_LA-RA_24BIT_CAL', 'ECG_Accel_LN_Z_CAL'], \n",
    "                    dtype={'ECG_Timestamp_Unix_CAL': 'float', 'ECG_ECG_LA-RA_24BIT_CAL': 'float', 'ECG_Accel_LN_Z_CAL': 'float'})\n",
    "            data.rename(columns={'ECG_Timestamp_Unix_CAL': 'index', 'ECG_ECG_LA-RA_24BIT_CAL': 'ECG', 'ECG_Accel_LN_Z_CAL': 'SCG'}, inplace=True)\n",
    "        elif re.match(r'./data/D2/UP-*', filename):\n",
    "            data = pd.read_csv(filename, \n",
    "                    sep=',', \n",
    "                    header=0, \n",
    "                    skiprows=[1],\n",
    "                    usecols=['ECG_ECG_LA-RA_24BIT_CAL', 'ECG_Accel_LN_Z_CAL'], \n",
    "                    dtype={'ECG_ECG_LA-RA_24BIT_CAL': 'float', 'ECG_Accel_LN_Z_CAL': 'float'})\n",
    "            data.rename(columns={'ECG_ECG_LA-RA_24BIT_CAL': 'ECG', 'ECG_Accel_LN_Z_CAL': 'SCG'}, inplace=True)\n",
    "\n",
    "            # The datetime index is not set correctly. Therefore, it has to be set set manually. The frequency was obtained from the original paper. Please refer to the thesis for further information.\n",
    "            frequency = 512\n",
    "            frequency_string = str(int(1/frequency*1000000000)) + 'N'\n",
    "            data['index'] = pd.date_range(start='1/1/1970', periods=data.shape[0], freq=frequency_string)\n",
    "        else:\n",
    "            return pd.DataFrame()\n",
    "\n",
    "        data['index'] = pd.to_datetime(data['index'], unit='ms')\n",
    "        data.set_index('index', inplace=True)\n",
    "\n",
    "        # Resample the data into the desired sampling rate.\n",
    "        data = data.resample(sampling_rate).mean()\n",
    "\n",
    "        # Split the data into groups with segment_size_samples samples.\n",
    "        data = pd.DataFrame([[x.ECG.to_numpy(), x.SCG.to_numpy()] for x in data.rolling(window=1024, step=128) if x.shape[0] == 1024 and not np.isnan(x.SCG).any() and not np.isnan(x.ECG).any()])\n",
    "        data.columns = ['ECG', 'SCG']\n",
    "\n",
    "        data['SCG'], _, _ = normalize(data['SCG'])\n",
    "        data['ECG'], _, _ = normalize(data['ECG'])\n",
    "\n",
    "        return data\n",
    "\n",
    "    # Loads the datasets denoted in the datasets parameter.\n",
    "    def __load_datasets(self):\n",
    "\n",
    "        data = pd.Series(dtype='object')\n",
    "\n",
    "        # Loads the CEBS dataset from the 'CEBS' directory in the directory folder.\n",
    "        if 'CEBS' in self.datasets:\n",
    "            directory = os.path.join(self.directory, 'CEBS')\n",
    "            filenames = list(dict.fromkeys([x[:-4] for x in glob.glob(f'{directory}/*[0-9][0-9][0-9].*')]))\n",
    "            data = pd.concat((self.__load_cebs(filename) for filename in filenames), ignore_index=True)\n",
    "\n",
    "        # Loads the D2 dataset from the 'D2' directory in the directory folder.\n",
    "        if 'D2' in self.datasets:\n",
    "            directory = os.path.join(self.directory, 'D2')\n",
    "            filenames = glob.glob(f'{directory}/*')\n",
    "            data2 = pd.concat((self.__load_d2(filename) for filename in filenames), ignore_index=True)\n",
    "            data = pd.concat((data, data2))\n",
    "\n",
    "        return data\n",
    "\n",
    "    # Returns a sample with the specified index and applies the transformation, if it is set.\n",
    "    def __getitem__(self, index):\n",
    "        sample = self.x_data[index].copy(), self.y_data[index].copy()\n",
    "\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "        \n",
    "        return sample\n",
    "    \n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.n_samples\n",
    "\n",
    "\n",
    "# Transformation class used to transform the numpy arrays to PyTorch tensors.\n",
    "class ToTensor:\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        inputs, targets = sample\n",
    "        return torch.from_numpy(inputs), torch.from_numpy(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1492b678",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loads the data and returns splitted test and train datasets\n",
    "def load_data(directory, datasets, transform, ecg=False):\n",
    "    dataset = SCGData(directory=directory, datasets=datasets, transform=transform, ecg=ecg)\n",
    "    train_size = int(0.8 * len(dataset))\n",
    "    test_size = len(dataset) - train_size\n",
    "    return torch.utils.data.random_split(dataset, [train_size, test_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "97834ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports the dataset and splits it into a train and test subset. \n",
    "train_dataset, test_dataset = load_data(directory=data_directory, datasets=['CEBS'], transform=ToTensor(), ecg=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b837dfa1",
   "metadata": {},
   "source": [
    "## Machine Learning Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ba01cc41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Input Shape               Output Shape\n",
       "==========================================================================================\n",
       "DeNoise1                                 [32, 1, 1024]             [32, 1, 1024]\n",
       "├─Sequential: 1-1                        [32, 1, 1024]             [32, 1, 1000]\n",
       "│    └─Conv1d: 2-1                       [32, 1, 1024]             [32, 128, 1018]\n",
       "│    └─BatchNorm1d: 2-2                  [32, 128, 1018]           [32, 128, 1018]\n",
       "│    └─ELU: 2-3                          [32, 128, 1018]           [32, 128, 1018]\n",
       "│    └─Conv1d: 2-4                       [32, 128, 1018]           [32, 64, 1012]\n",
       "│    └─BatchNorm1d: 2-5                  [32, 64, 1012]            [32, 64, 1012]\n",
       "│    └─ELU: 2-6                          [32, 64, 1012]            [32, 64, 1012]\n",
       "│    └─Conv1d: 2-7                       [32, 64, 1012]            [32, 32, 1006]\n",
       "│    └─BatchNorm1d: 2-8                  [32, 32, 1006]            [32, 32, 1006]\n",
       "│    └─ELU: 2-9                          [32, 32, 1006]            [32, 32, 1006]\n",
       "│    └─Conv1d: 2-10                      [32, 32, 1006]            [32, 1, 1000]\n",
       "│    └─BatchNorm1d: 2-11                 [32, 1, 1000]             [32, 1, 1000]\n",
       "│    └─ELU: 2-12                         [32, 1, 1000]             [32, 1, 1000]\n",
       "├─Sequential: 1-2                        [32, 1, 1000]             [32, 1, 1024]\n",
       "│    └─ConvTranspose1d: 2-13             [32, 1, 1000]             [32, 32, 1006]\n",
       "│    └─BatchNorm1d: 2-14                 [32, 32, 1006]            [32, 32, 1006]\n",
       "│    └─ELU: 2-15                         [32, 32, 1006]            [32, 32, 1006]\n",
       "│    └─ConvTranspose1d: 2-16             [32, 32, 1006]            [32, 64, 1012]\n",
       "│    └─BatchNorm1d: 2-17                 [32, 64, 1012]            [32, 64, 1012]\n",
       "│    └─ELU: 2-18                         [32, 64, 1012]            [32, 64, 1012]\n",
       "│    └─ConvTranspose1d: 2-19             [32, 64, 1012]            [32, 128, 1018]\n",
       "│    └─BatchNorm1d: 2-20                 [32, 128, 1018]           [32, 128, 1018]\n",
       "│    └─ELU: 2-21                         [32, 128, 1018]           [32, 128, 1018]\n",
       "│    └─ConvTranspose1d: 2-22             [32, 128, 1018]           [32, 1, 1024]\n",
       "│    └─BatchNorm1d: 2-23                 [32, 1, 1024]             [32, 1, 1024]\n",
       "│    └─ELU: 2-24                         [32, 1, 1024]             [32, 1, 1024]\n",
       "│    └─Conv1d: 2-25                      [32, 1, 1024]             [32, 1, 1024]\n",
       "│    └─Tanh: 2-26                        [32, 1, 1024]             [32, 1, 1024]\n",
       "==========================================================================================\n",
       "Total params: 146,958\n",
       "Trainable params: 146,958\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 4.74\n",
       "==========================================================================================\n",
       "Input size (MB): 0.13\n",
       "Forward/backward pass size (MB): 234.02\n",
       "Params size (MB): 0.59\n",
       "Estimated Total Size (MB): 234.74\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class DeNoise1(nn.Module):\n",
    "    def __init__(self, layer_size=128):\n",
    "        super(DeNoise1, self).__init__()\n",
    "\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv1d(1, layer_size, 7, stride=1),\n",
    "            nn.BatchNorm1d(layer_size),\n",
    "            nn.ELU(),\n",
    "            nn.Conv1d(layer_size, int(layer_size/2), 7, stride=1),\n",
    "            nn.BatchNorm1d(int(layer_size/2)),\n",
    "            nn.ELU(),\n",
    "            nn.Conv1d(int(layer_size/2), int(layer_size/4), 7, stride=1),\n",
    "            nn.BatchNorm1d(int(layer_size/4)),\n",
    "            nn.ELU(),\n",
    "            nn.Conv1d(int(layer_size/4), 1, 7, stride=1),\n",
    "            nn.BatchNorm1d(1),\n",
    "            nn.ELU()\n",
    "        )\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose1d(1, int(layer_size/4), 7, stride=1),\n",
    "            nn.BatchNorm1d(int(layer_size/4)),\n",
    "            nn.ELU(),\n",
    "            nn.ConvTranspose1d(int(layer_size/4), int(layer_size/2), 7, stride=1),\n",
    "            nn.BatchNorm1d(int(layer_size/2)),\n",
    "            nn.ELU(),\n",
    "            nn.ConvTranspose1d(int(layer_size/2), layer_size, 7, stride=1),\n",
    "            nn.BatchNorm1d(layer_size),\n",
    "            nn.ELU(),\n",
    "            nn.ConvTranspose1d(layer_size, 1, 7, stride=1), \n",
    "            nn.BatchNorm1d(1),\n",
    "            nn.ELU(),\n",
    "            nn.Conv1d(1, 1, 7, stride=1, padding='same'),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded\n",
    "\n",
    "# Prints the structure of the Autoencoder\n",
    "torchinfo.summary(DeNoise1(), (32, 1, segment_size_samples), col_names=('input_size', 'output_size'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "031c1a44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Input Shape               Output Shape\n",
       "==========================================================================================\n",
       "DeNoise2                                 [32, 1, 1024]             [32, 1, 1024]\n",
       "├─Sequential: 1-1                        [32, 1, 1024]             [32, 1, 497]\n",
       "│    └─Conv1d: 2-1                       [32, 1, 1024]             [32, 128, 1018]\n",
       "│    └─BatchNorm1d: 2-2                  [32, 128, 1018]           [32, 128, 1018]\n",
       "│    └─ELU: 2-3                          [32, 128, 1018]           [32, 128, 1018]\n",
       "│    └─Conv1d: 2-4                       [32, 128, 1018]           [32, 32, 1012]\n",
       "│    └─BatchNorm1d: 2-5                  [32, 32, 1012]            [32, 32, 1012]\n",
       "│    └─ELU: 2-6                          [32, 32, 1012]            [32, 32, 1012]\n",
       "│    └─Conv1d: 2-7                       [32, 32, 1012]            [32, 16, 503]\n",
       "│    └─BatchNorm1d: 2-8                  [32, 16, 503]             [32, 16, 503]\n",
       "│    └─ELU: 2-9                          [32, 16, 503]             [32, 16, 503]\n",
       "│    └─Conv1d: 2-10                      [32, 16, 503]             [32, 1, 497]\n",
       "│    └─BatchNorm1d: 2-11                 [32, 1, 497]              [32, 1, 497]\n",
       "│    └─ELU: 2-12                         [32, 1, 497]              [32, 1, 497]\n",
       "├─Sequential: 1-2                        [32, 1, 497]              [32, 1, 1024]\n",
       "│    └─ConvTranspose1d: 2-13             [32, 1, 497]              [32, 16, 503]\n",
       "│    └─BatchNorm1d: 2-14                 [32, 16, 503]             [32, 16, 503]\n",
       "│    └─ELU: 2-15                         [32, 16, 503]             [32, 16, 503]\n",
       "│    └─ConvTranspose1d: 2-16             [32, 16, 503]             [32, 32, 1012]\n",
       "│    └─BatchNorm1d: 2-17                 [32, 32, 1012]            [32, 32, 1012]\n",
       "│    └─ELU: 2-18                         [32, 32, 1012]            [32, 32, 1012]\n",
       "│    └─ConvTranspose1d: 2-19             [32, 32, 1012]            [32, 128, 1018]\n",
       "│    └─BatchNorm1d: 2-20                 [32, 128, 1018]           [32, 128, 1018]\n",
       "│    └─ELU: 2-21                         [32, 128, 1018]           [32, 128, 1018]\n",
       "│    └─ConvTranspose1d: 2-22             [32, 128, 1018]           [32, 1, 1024]\n",
       "│    └─BatchNorm1d: 2-23                 [32, 1, 1024]             [32, 1, 1024]\n",
       "│    └─ELU: 2-24                         [32, 1, 1024]             [32, 1, 1024]\n",
       "│    └─Conv1d: 2-25                      [32, 1, 1024]             [32, 1, 1024]\n",
       "│    └─Tanh: 2-26                        [32, 1, 1024]             [32, 1, 1024]\n",
       "==========================================================================================\n",
       "Total params: 67,598\n",
       "Trainable params: 67,598\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 2.11\n",
       "==========================================================================================\n",
       "Input size (MB): 0.13\n",
       "Forward/backward pass size (MB): 175.87\n",
       "Params size (MB): 0.27\n",
       "Estimated Total Size (MB): 176.28\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class DeNoise2(nn.Module):\n",
    "    def __init__(self, layer_size=128):\n",
    "        super(DeNoise2, self).__init__()\n",
    "\n",
    "        # (i-k +2*p)/s+1\n",
    "        # (i-1)*s+k-2p\n",
    "\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv1d(1, layer_size, 7, stride=1, padding=0),\n",
    "            nn.BatchNorm1d(layer_size),\n",
    "            nn.ELU(),\n",
    "            nn.Conv1d(layer_size, int(layer_size/4), 7, stride=1, padding=0),\n",
    "            nn.BatchNorm1d(int(layer_size/4)),\n",
    "            nn.ELU(),\n",
    "            nn.Conv1d(int(layer_size/4), int(layer_size/8), 7, stride=2, padding=0),\n",
    "            nn.BatchNorm1d(int(layer_size/8)),\n",
    "            nn.ELU(),\n",
    "            nn.Conv1d(int(layer_size/8), 1, 7, stride=1, padding=0),\n",
    "            nn.BatchNorm1d(1),\n",
    "            nn.ELU()\n",
    "        )\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose1d(1, int(layer_size/8), 7, stride=1, padding=0),\n",
    "            nn.BatchNorm1d(int(layer_size/8)),\n",
    "            nn.ELU(),\n",
    "            nn.ConvTranspose1d(int(layer_size/8), int(layer_size/4), 7, stride=2, output_padding=1),\n",
    "            nn.BatchNorm1d(int(layer_size/4)),\n",
    "            nn.ELU(),\n",
    "            nn.ConvTranspose1d(int(layer_size/4), int(layer_size), 7, stride=1, output_padding=0),\n",
    "            nn.BatchNorm1d(int(layer_size)),\n",
    "            nn.ELU(),\n",
    "            nn.ConvTranspose1d(int(layer_size), 1, 7, stride=1, padding=0), \n",
    "            nn.BatchNorm1d(1),\n",
    "            nn.ELU(),\n",
    "            nn.Conv1d(1, 1, 7, stride=1, padding='same'),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded\n",
    "\n",
    "# Prints the structure of the Autoencoder\n",
    "torchinfo.summary(DeNoise2(), (32, 1, segment_size_samples), col_names=('input_size', 'output_size'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ba01cc41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Input Shape               Output Shape\n",
       "==========================================================================================\n",
       "DeNoise3                                 [32, 1, 1024]             [32, 1, 1024]\n",
       "├─Sequential: 1-1                        [32, 1, 1024]             [32, 1, 5]\n",
       "│    └─Conv1d: 2-1                       [32, 1, 1024]             [32, 128, 505]\n",
       "│    └─BatchNorm1d: 2-2                  [32, 128, 505]            [32, 128, 505]\n",
       "│    └─ELU: 2-3                          [32, 128, 505]            [32, 128, 505]\n",
       "│    └─Conv1d: 2-4                       [32, 128, 505]            [32, 64, 246]\n",
       "│    └─BatchNorm1d: 2-5                  [32, 64, 246]             [32, 64, 246]\n",
       "│    └─ELU: 2-6                          [32, 64, 246]             [32, 64, 246]\n",
       "│    └─Conv1d: 2-7                       [32, 64, 246]             [32, 64, 117]\n",
       "│    └─BatchNorm1d: 2-8                  [32, 64, 117]             [32, 64, 117]\n",
       "│    └─ELU: 2-9                          [32, 64, 117]             [32, 64, 117]\n",
       "│    └─Conv1d: 2-10                      [32, 64, 117]             [32, 64, 52]\n",
       "│    └─BatchNorm1d: 2-11                 [32, 64, 52]              [32, 64, 52]\n",
       "│    └─ELU: 2-12                         [32, 64, 52]              [32, 64, 52]\n",
       "│    └─Conv1d: 2-13                      [32, 64, 52]              [32, 128, 20]\n",
       "│    └─BatchNorm1d: 2-14                 [32, 128, 20]             [32, 128, 20]\n",
       "│    └─ELU: 2-15                         [32, 128, 20]             [32, 128, 20]\n",
       "│    └─Conv1d: 2-16                      [32, 128, 20]             [32, 1, 5]\n",
       "│    └─BatchNorm1d: 2-17                 [32, 1, 5]                [32, 1, 5]\n",
       "│    └─ELU: 2-18                         [32, 1, 5]                [32, 1, 5]\n",
       "├─Sequential: 1-2                        [32, 1, 5]                [32, 1, 1024]\n",
       "│    └─ConvTranspose1d: 2-19             [32, 1, 5]                [32, 1, 20]\n",
       "│    └─BatchNorm1d: 2-20                 [32, 1, 20]               [32, 1, 20]\n",
       "│    └─ELU: 2-21                         [32, 1, 20]               [32, 1, 20]\n",
       "│    └─ConvTranspose1d: 2-22             [32, 1, 20]               [32, 128, 52]\n",
       "│    └─BatchNorm1d: 2-23                 [32, 128, 52]             [32, 128, 52]\n",
       "│    └─ELU: 2-24                         [32, 128, 52]             [32, 128, 52]\n",
       "│    └─ConvTranspose1d: 2-25             [32, 128, 52]             [32, 64, 118]\n",
       "│    └─BatchNorm1d: 2-26                 [32, 64, 118]             [32, 64, 118]\n",
       "│    └─ELU: 2-27                         [32, 64, 118]             [32, 64, 118]\n",
       "│    └─ConvTranspose1d: 2-28             [32, 64, 118]             [32, 64, 250]\n",
       "│    └─BatchNorm1d: 2-29                 [32, 64, 250]             [32, 64, 250]\n",
       "│    └─ELU: 2-30                         [32, 64, 250]             [32, 64, 250]\n",
       "│    └─ConvTranspose1d: 2-31             [32, 64, 250]             [32, 64, 514]\n",
       "│    └─BatchNorm1d: 2-32                 [32, 64, 514]             [32, 64, 514]\n",
       "│    └─ELU: 2-33                         [32, 64, 514]             [32, 64, 514]\n",
       "│    └─ConvTranspose1d: 2-34             [32, 64, 514]             [32, 128, 1039]\n",
       "│    └─BatchNorm1d: 2-35                 [32, 128, 1039]           [32, 128, 1039]\n",
       "│    └─ELU: 2-36                         [32, 128, 1039]           [32, 128, 1039]\n",
       "│    └─Conv1d: 2-37                      [32, 128, 1039]           [32, 1, 1024]\n",
       "│    └─ReLU: 2-38                        [32, 1, 1024]             [32, 1, 1024]\n",
       "==========================================================================================\n",
       "Total params: 797,335\n",
       "Trainable params: 797,335\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 8.04\n",
       "==========================================================================================\n",
       "Input size (MB): 0.13\n",
       "Forward/backward pass size (MB): 148.68\n",
       "Params size (MB): 3.19\n",
       "Estimated Total Size (MB): 152.00\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class DeNoise3(nn.Module):\n",
    "    def __init__(self, kernel_size=16, filters_1=128, filters_2=64):\n",
    "        super(DeNoise3, self).__init__()\n",
    "        #self.p1 = segment_size_samples/2 + 7\n",
    "        #self.p2 = segment_size_samples/64 + 7\n",
    "        # (i-k +2*p)/s+1\n",
    "        # (i-1)*s+k-2p\n",
    "\n",
    "        self.kernel_size = kernel_size\n",
    "        self.filters_1 = filters_1\n",
    "        self.filters_2 = filters_2\n",
    "\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv1d(1, filters_1, kernel_size, stride=2),\n",
    "            nn.BatchNorm1d(filters_1),\n",
    "            nn.ELU(),\n",
    "            nn.Conv1d(filters_1, filters_2, kernel_size, stride=2, padding=1),\n",
    "            nn.BatchNorm1d(filters_2),\n",
    "            nn.ELU(),\n",
    "            nn.Conv1d(filters_2, filters_2, kernel_size, stride=2, padding=1),\n",
    "            nn.BatchNorm1d(filters_2),\n",
    "            nn.ELU(),\n",
    "            nn.Conv1d(filters_2, filters_2, kernel_size, stride=2, padding=1),\n",
    "            nn.BatchNorm1d(filters_2),\n",
    "            nn.ELU(),\n",
    "            nn.Conv1d(filters_2, filters_1, kernel_size, stride=2, padding=1),\n",
    "            nn.BatchNorm1d(filters_1),\n",
    "            nn.ELU(),\n",
    "            nn.Conv1d(filters_1, 1, kernel_size, stride=1),\n",
    "            nn.BatchNorm1d(1),\n",
    "            nn.ELU()\n",
    "        )\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose1d(1, 1, kernel_size, stride=1),\n",
    "            nn.BatchNorm1d(1),\n",
    "            nn.ELU(),\n",
    "            nn.ConvTranspose1d(1, filters_1, kernel_size, stride=2, padding=1),\n",
    "            nn.BatchNorm1d(filters_1),\n",
    "            nn.ELU(),\n",
    "            nn.ConvTranspose1d(filters_1, filters_2, kernel_size, stride=2, padding=0),\n",
    "            nn.BatchNorm1d(filters_2),\n",
    "            nn.ELU(),\n",
    "            nn.ConvTranspose1d(filters_2, filters_2, kernel_size, stride=2, padding=0),\n",
    "            nn.BatchNorm1d(filters_2),\n",
    "            nn.ELU(),\n",
    "            nn.ConvTranspose1d(filters_2, filters_2, kernel_size, stride=2, padding=0),\n",
    "            nn.BatchNorm1d(filters_2),\n",
    "            nn.ELU(),\n",
    "            nn.ConvTranspose1d(filters_2, filters_1, kernel_size, stride=2, padding=2, output_padding=1),\n",
    "            nn.BatchNorm1d(filters_1),\n",
    "            nn.ELU(),\n",
    "            nn.Conv1d(filters_1, 1, kernel_size, stride=1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x = x.view(-1, 1, segment_size_samples)\n",
    "        encoded = self.encoder(x)\n",
    "        #encoded = encoded.view(-1, 1, segment_size_samples//16, 1)\n",
    "        #encoded = nn.functional.pad(encoded, (0, 0, 1, 0))\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded\n",
    "\n",
    "#print(segment_size_samples/2 + 7)\n",
    "#print(segment_size_samples/(2*8) + 7)\n",
    "torchinfo.summary(DeNoise3(), (32, 1, segment_size_samples), col_names=('input_size', 'output_size'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc39d04",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1c7816ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(config, train_dataset, model_num, is_tune=False, data_id=None, checkpoint_dir=None, data_dir=None):\n",
    "\n",
    "    if model_num in [1]:\n",
    "        model = DeNoise1(layer_size=config['layer_size'])\n",
    "    elif model_num in [2, 3]:\n",
    "        model = DeNoise2(layer_size=config['layer_size'])\n",
    "    elif model_num in [4]:\n",
    "        model = DeNoise3()\n",
    "    model = model.to(device)\n",
    "\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=config['lr'], weight_decay=config['wd'])\n",
    "\n",
    "    # if checkpoint_dir != None:\n",
    "    #    model_state, optimizer_state = torch.load(os.path.join(checkpoint_dir, \"checkpoint\"))\n",
    "    #    model.load_state_dict(model_state)\n",
    "    #    optimizer.load_state_dict(optimizer_state)\n",
    "\n",
    "    if data_id:\n",
    "        train_dataset = get(data_id)\n",
    "\n",
    "    test_size = int(0.8 * len(train_dataset))\n",
    "    val_size = len(train_dataset) - test_size\n",
    "    train_dataset, val_dataset = torch.utils.data.random_split(train_dataset, [test_size, val_size])\n",
    "\n",
    "    train_loader = DataLoader(dataset=train_dataset, batch_size=config['batch_size'], shuffle=True, num_workers=4, pin_memory=True)\n",
    "    val_loader = DataLoader(dataset=val_dataset, batch_size=config['batch_size'], shuffle=True, num_workers=4, pin_memory=True)\n",
    "\n",
    "    n_total_steps = len(train_loader)\n",
    "    min_val_loss = np.inf\n",
    "\n",
    "    train_loss_values = []\n",
    "    val_loss_values = []\n",
    "    epoch_values = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        \n",
    "        train_loss = 0.0\n",
    "        train_steps = 0\n",
    "        for i, (inputs, lables) in enumerate(train_loader):\n",
    "            \n",
    "            #if model_num == 3:\n",
    "            #    inputs = denoise_wavelet(inputs, method='BayesShrink', mode='soft', wavelet_levels=1, wavelet='sym8', rescale_sigma='True')\n",
    "                \n",
    "            # inputs, lables = torch.from_numpy(inputs), torch.from_numpy(lables)\n",
    "            inputs, lables = inputs.to(device, dtype=torch.float), lables.to(device, dtype=torch.float)\n",
    "            inputs, lables = inputs.view(-1, 1, segment_size_samples), lables.view(-1, 1, segment_size_samples)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output = model(inputs)\n",
    "            loss = criterion(output, lables)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            train_steps += 1\n",
    "        \n",
    "        train_loss_values.append(train_loss)\n",
    "\n",
    "        val_loss = 0.0\n",
    "        val_steps = 0\n",
    "        for i, (inputs, lables) in enumerate(val_loader):\n",
    "\n",
    "            #if model_num == 3:\n",
    "            #    inputs = denoise_wavelet(inputs, method='BayesShrink', mode='soft', wavelet_levels=1, wavelet='sym8', rescale_sigma='True')\n",
    "\n",
    "            # inputs, lables = torch.from_numpy(inputs), torch.from_numpy(lables)\n",
    "            inputs, lables = inputs.to(device, dtype=torch.float), lables.to(device, dtype=torch.float)\n",
    "            inputs, lables = inputs.view(-1, 1, segment_size_samples), lables.view(-1, 1, segment_size_samples)\n",
    "\n",
    "            output = model(inputs)\n",
    "            loss = criterion(output, lables)\n",
    "            val_loss += loss.item()\n",
    "            val_steps += 1\n",
    "            \n",
    "        val_loss_values.append(val_loss)\n",
    "        epoch_values.append(epoch)\n",
    "\n",
    "        if is_tune:\n",
    "            with tune.checkpoint_dir(epoch) as checkpoint_dir:\n",
    "                path = os.path.join(checkpoint_dir, 'checkpoint')\n",
    "                torch.save((model.state_dict(), optimizer.state_dict()), path)\n",
    "            \n",
    "            tune.report(loss=(val_loss / val_steps))\n",
    "        else:\n",
    "            print(f'epoch {epoch + 1} / {num_epochs}, train loss = {(train_loss / len(train_loader)):.10f}, val loss = {(val_loss / len(val_loader)):.10f}')\n",
    "            pd.DataFrame({'epoch': epoch_values,'train_loss': train_loss_values, 'val_loss': val_loss_values}).to_csv(f'./models/loss_{model_num}.csv') \n",
    "            \n",
    "            if min_val_loss > val_loss:\n",
    "                \n",
    "                print(f'\\tval loss decreased from {min_val_loss:.10f} to {val_loss:.10f}')\n",
    "                min_val_loss = val_loss\n",
    "                torch.save(model.state_dict(), os.path.join(model_directory, f'model_{model_num}.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c1549df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the correct noise levels for the training process.\n",
    "train_dataset.dataset.add_noise(train_target_snr_dbs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c515a47d",
   "metadata": {},
   "source": [
    "{'lr': 0.0018729000345412963, 'wd': 0, 'batch_size': 8, 'layer_size': 256} 0.0004914292857526488\n",
    "{'lr': 0.0018437162360595998, 'wd': 0, 'batch_size': 8, 'layer_size': 128} 0.0007439919008643882\n",
    "{'lr': 0.0006948120282769452, 'wd': 0, 'batch_size': 16, 'layer_size': 128} 0.0013009571703150868\n",
    "\n",
    "{'lr': 0.0017898461100052906, 'wd': 0, 'batch_size': 8, 'layer_size': 128} 0.0015937495978413632\n",
    "{'lr': 0.004531902539657156, 'wd': 0, 'batch_size': 8, 'layer_size': 256} 0.0005863353168515718 w/o bandpass, 10\n",
    "{'lr': 0.0017668188704620857, 'wd': 0, 'batch_size': 8, 'layer_size': 256} 0.0009116247971238728 bandpass, 10\n",
    "{'lr': 0.006820280279552952, 'wd': 0, 'batch_size': 8, 'layer_size': 256} 0.0004986349987892337 with 2x stride 2\n",
    "{'lr': 0.007810417589096403, 'wd': 0, 'batch_size': 8, 'layer_size': 256} 0.0004332348386333898 with 1x stride 2\n",
    "{'lr': 0.0015365439418637585, 'wd': 0, 'batch_size': 8, 'layer_size': 128} 0.0007714835297364866\n",
    "{'lr': 0.02716233959851866, 'wd': 0, 'batch_size': 32, 'layer_size': 128} 0.0013283919510080145\n",
    "{'lr': 0.0019890548242081614, 'wd': 0, 'batch_size': 16, 'layer_size': 128} 0.00144807931687008\n",
    "{'lr': 0.0038625945811403732, 'wd': 0, 'batch_size': 16, 'layer_size': 128} 0.0013378030157384826\n",
    "{'lr': 0.0017112891648358517, 'wd': 0, 'batch_size': 32, 'layer_size': 128} 0.0019708356504062456\n",
    "{'lr': 0.0029673206198941445, 'wd': 0, 'batch_size': 8, 'layer_size': 128} 0.0008134577474093409\n",
    "{'lr': 0.00032813453637735567, 'wd': 0, 'batch_size': 64, 'layer_size': 128} 0.0008\n",
    "{'lr': 0.0011704653180570925, 'wd': 0, 'batch_size': 8, 'layer_size': 128} 0.0010375047129388723\n",
    "{'lr': 0.0025766834278764987, 'wd': 0, 'batch_size': 16, 'layer_size': 128} 0.0018318614236014928"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "354f4492",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 / 256, train loss = 0.1018572955, val loss = 0.0698825533\n",
      "\tval loss decreased from inf to 38.8546996601\n",
      "epoch 2 / 256, train loss = 0.0612230092, val loss = 0.0571525194\n",
      "\tval loss decreased from 38.8546996601 to 31.7768007740\n",
      "epoch 3 / 256, train loss = 0.0540803427, val loss = 0.0571288037\n",
      "\tval loss decreased from 31.7768007740 to 31.7636148781\n",
      "epoch 4 / 256, train loss = 0.0494425441, val loss = 0.0470474750\n",
      "\tval loss decreased from 31.7636148781 to 26.1583960745\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# train({'lr': 0.002, 'wd': 0, 'batch_size': 8, 'layer_size': 256}, train_dataset, 1)\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m train({\u001b[39m'\u001b[39;49m\u001b[39mlr\u001b[39;49m\u001b[39m'\u001b[39;49m: \u001b[39m0.001\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mwd\u001b[39;49m\u001b[39m'\u001b[39;49m: \u001b[39m0\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mbatch_size\u001b[39;49m\u001b[39m'\u001b[39;49m: \u001b[39m16\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mlayer_size\u001b[39;49m\u001b[39m'\u001b[39;49m: \u001b[39m128\u001b[39;49m}, train_dataset, \u001b[39m2\u001b[39;49m)\n\u001b[1;32m      3\u001b[0m \u001b[39m# train({'lr': 0.0005, 'wd': 0, 'batch_size': 8, 'layer_size': 128}, train_dataset, 3)\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[39m# train({'lr': 0.005, 'wd': 0, 'batch_size': 8, 'layer_size': 128}, train_dataset, 4)\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[32], line 53\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(config, train_dataset, model_num, is_tune, data_id, checkpoint_dir, data_dir)\u001b[0m\n\u001b[1;32m     51\u001b[0m loss \u001b[39m=\u001b[39m criterion(output, lables)\n\u001b[1;32m     52\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n\u001b[0;32m---> 53\u001b[0m optimizer\u001b[39m.\u001b[39;49mstep()\n\u001b[1;32m     55\u001b[0m train_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mitem()\n\u001b[1;32m     56\u001b[0m train_steps \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/thesis-project-i_Sg-Li3/lib/python3.10/site-packages/torch/optim/optimizer.py:140\u001b[0m, in \u001b[0;36mOptimizer._hook_for_profile.<locals>.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m profile_name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mOptimizer.step#\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m.step\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(obj\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m)\n\u001b[1;32m    139\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mautograd\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mrecord_function(profile_name):\n\u001b[0;32m--> 140\u001b[0m     out \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    141\u001b[0m     obj\u001b[39m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    142\u001b[0m     \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/thesis-project-i_Sg-Li3/lib/python3.10/site-packages/torch/optim/optimizer.py:23\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     22\u001b[0m     torch\u001b[39m.\u001b[39mset_grad_enabled(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdefaults[\u001b[39m'\u001b[39m\u001b[39mdifferentiable\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m---> 23\u001b[0m     ret \u001b[39m=\u001b[39m func(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     24\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     25\u001b[0m     torch\u001b[39m.\u001b[39mset_grad_enabled(prev_grad)\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/thesis-project-i_Sg-Li3/lib/python3.10/site-packages/torch/optim/adam.py:234\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure, grad_scaler)\u001b[0m\n\u001b[1;32m    231\u001b[0m                 \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39m`requires_grad` is not supported for `step` in differentiable mode\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    232\u001b[0m             state_steps\u001b[39m.\u001b[39mappend(state[\u001b[39m'\u001b[39m\u001b[39mstep\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m--> 234\u001b[0m     adam(params_with_grad,\n\u001b[1;32m    235\u001b[0m          grads,\n\u001b[1;32m    236\u001b[0m          exp_avgs,\n\u001b[1;32m    237\u001b[0m          exp_avg_sqs,\n\u001b[1;32m    238\u001b[0m          max_exp_avg_sqs,\n\u001b[1;32m    239\u001b[0m          state_steps,\n\u001b[1;32m    240\u001b[0m          amsgrad\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mamsgrad\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    241\u001b[0m          beta1\u001b[39m=\u001b[39;49mbeta1,\n\u001b[1;32m    242\u001b[0m          beta2\u001b[39m=\u001b[39;49mbeta2,\n\u001b[1;32m    243\u001b[0m          lr\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mlr\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    244\u001b[0m          weight_decay\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mweight_decay\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    245\u001b[0m          eps\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39meps\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    246\u001b[0m          maximize\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mmaximize\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    247\u001b[0m          foreach\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mforeach\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    248\u001b[0m          capturable\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mcapturable\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    249\u001b[0m          differentiable\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mdifferentiable\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    250\u001b[0m          fused\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mfused\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    251\u001b[0m          grad_scale\u001b[39m=\u001b[39;49mgrad_scale,\n\u001b[1;32m    252\u001b[0m          found_inf\u001b[39m=\u001b[39;49mfound_inf)\n\u001b[1;32m    254\u001b[0m \u001b[39mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/thesis-project-i_Sg-Li3/lib/python3.10/site-packages/torch/optim/adam.py:300\u001b[0m, in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    297\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    298\u001b[0m     func \u001b[39m=\u001b[39m _single_tensor_adam\n\u001b[0;32m--> 300\u001b[0m func(params,\n\u001b[1;32m    301\u001b[0m      grads,\n\u001b[1;32m    302\u001b[0m      exp_avgs,\n\u001b[1;32m    303\u001b[0m      exp_avg_sqs,\n\u001b[1;32m    304\u001b[0m      max_exp_avg_sqs,\n\u001b[1;32m    305\u001b[0m      state_steps,\n\u001b[1;32m    306\u001b[0m      amsgrad\u001b[39m=\u001b[39;49mamsgrad,\n\u001b[1;32m    307\u001b[0m      beta1\u001b[39m=\u001b[39;49mbeta1,\n\u001b[1;32m    308\u001b[0m      beta2\u001b[39m=\u001b[39;49mbeta2,\n\u001b[1;32m    309\u001b[0m      lr\u001b[39m=\u001b[39;49mlr,\n\u001b[1;32m    310\u001b[0m      weight_decay\u001b[39m=\u001b[39;49mweight_decay,\n\u001b[1;32m    311\u001b[0m      eps\u001b[39m=\u001b[39;49meps,\n\u001b[1;32m    312\u001b[0m      maximize\u001b[39m=\u001b[39;49mmaximize,\n\u001b[1;32m    313\u001b[0m      capturable\u001b[39m=\u001b[39;49mcapturable,\n\u001b[1;32m    314\u001b[0m      differentiable\u001b[39m=\u001b[39;49mdifferentiable,\n\u001b[1;32m    315\u001b[0m      grad_scale\u001b[39m=\u001b[39;49mgrad_scale,\n\u001b[1;32m    316\u001b[0m      found_inf\u001b[39m=\u001b[39;49mfound_inf)\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/thesis-project-i_Sg-Li3/lib/python3.10/site-packages/torch/optim/adam.py:353\u001b[0m, in \u001b[0;36m_single_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[1;32m    350\u001b[0m \u001b[39m# update step\u001b[39;00m\n\u001b[1;32m    351\u001b[0m step_t \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m--> 353\u001b[0m \u001b[39mif\u001b[39;00m weight_decay \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    354\u001b[0m     grad \u001b[39m=\u001b[39m grad\u001b[39m.\u001b[39madd(param, alpha\u001b[39m=\u001b[39mweight_decay)\n\u001b[1;32m    356\u001b[0m \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39mis_complex(param):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# train({'lr': 0.002, 'wd': 0, 'batch_size': 8, 'layer_size': 256}, train_dataset, 1)\n",
    "train({'lr': 0.001, 'wd': 0, 'batch_size': 16, 'layer_size': 128}, train_dataset, 2)\n",
    "# train({'lr': 0.0005, 'wd': 0, 'batch_size': 8, 'layer_size': 128}, train_dataset, 3)\n",
    "# train({'lr': 0.005, 'wd': 0, 'batch_size': 8, 'layer_size': 128}, train_dataset, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "550d9c55",
   "metadata": {},
   "source": [
    "## Hyperparametertuning\n",
    "\n",
    "The following code cell implements the hyperparametertuning. It was modeled after a [tutorial](https://pytorch.org/tutorials/beginner/hyperparameter_tuning_tutorial.html) by PyTorch, using RayTune as a tool for hyperparameter tuning. For optimizing the hyperparameters, the `ASHAScheduler` is being used and the loss should be minimized. The configuration defines the hyperparameters to be optimized. Here only the learning rate `lr`, the batch size `batch_size` and the layer size `layer_size` of the models will be taken into consideration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd2406ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hypertuning(dataset, config, num_samples, max_num_epochs, model_num):\n",
    "\n",
    "    # train_dataset.dataset.add_noise(train_target_snr_dbs)\n",
    "    scheduler = ASHAScheduler(metric='loss', mode='min', max_t=max_num_epochs, grace_period=1, reduction_factor=2)\n",
    "    reporter = CLIReporter(metric_columns=['loss', 'training_iteration'])\n",
    "    data_id = put(dataset)\n",
    "    result = tune.run(\n",
    "        partial(train, train_dataset=None, model_num=model_num, is_tune=True, data_id=data_id, checkpoint_dir=None, data_dir=None),\n",
    "        resources_per_trial={'cpu': 8, 'gpu': 1},\n",
    "        config=config,\n",
    "        num_samples=num_samples,\n",
    "        scheduler=scheduler,\n",
    "        progress_reporter=reporter\n",
    "    )\n",
    "\n",
    "    best_trial = result.get_best_trial('loss', 'min', 'last')\n",
    "    print(\"Best trial config: {}\".format(best_trial.config))\n",
    "    print(\"Best trial final validation loss: {}\".format(best_trial.last_result[\"loss\"]))\n",
    "\n",
    "    best_trained_model =  DeNoise2().to(device)\n",
    "\n",
    "    best_checkpoint_dir = best_trial.checkpoint.dir_or_data\n",
    "    model_state, optimizer_state = torch.load(os.path.join(best_checkpoint_dir, 'checkpoint'))\n",
    "    best_trained_model.load_state_dict(model_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cfe8d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'lr': tune.loguniform(1e-4, 1e-1),\n",
    "    'wd': 0,\n",
    "    'batch_size': tune.choice([8, 64, 128]),\n",
    "    'layer_size': tune.choice([128, 256])\n",
    "}\n",
    "\n",
    "# hypertuning(train_dataset, config, num_samples=64, max_num_epochs=32, model_num=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21410168",
   "metadata": {},
   "source": [
    "## Testing and Evaluation\n",
    "\n",
    "The following code cells are used for testing and evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3d3bbad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here, some evaluation metrics are implemented.\n",
    "\n",
    "# Mean-Squared Error\n",
    "def mse(signal_clean, signal_noisy):\n",
    "    return mean_squared_error(signal_clean, signal_noisy)\n",
    "\n",
    "# Mean-Absolute Error\n",
    "def mae(signal_clean, signal_noisy):\n",
    "    return mean_absolute_error(signal_clean, signal_noisy)\n",
    "\n",
    "# Root Mean-Squared Error\n",
    "def rmse(signal_clean, signal_noisy):\n",
    "    return np.sqrt(mse(signal_clean, signal_noisy))\n",
    "\n",
    "# Signal-to-noise ratio\n",
    "def snr(signal_clean, signal_noisy):\n",
    "    return 10 * np.log10(np.sum(signal_clean ** 2) / (np.sum((signal_noisy - signal_clean) ** 2)))\n",
    "\n",
    "# Peak signal-to-noise ratio\n",
    "def psnr(signal_clean, signal_noisy):\n",
    "    max_clean = np.max(signal_clean)\n",
    "    rmse_val = rmse(signal_clean, signal_noisy)\n",
    "    return 20 * np.log10(max_clean / rmse_val)\n",
    "\n",
    "# Root mean squared difference\n",
    "def prd(signal_clean, signal_noisy):\n",
    "    return np.sqrt(np.sum((signal_clean - signal_noisy) ** 2) / np.sum(signal_clean ** 2)) * 100\n",
    "\n",
    "# Cross-Correlation\n",
    "def xcorr(signal_clean, signal_noisy):\n",
    "    return np.mean(ccf(signal_clean, signal_noisy, adjusted=False))\n",
    "\n",
    "# Pearson Correlation Coefficient\n",
    "def pcorr(signal_clean, signal_noisy):\n",
    "    return np.corrcoef(signal_clean, signal_noisy)[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd42bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_result_bar(name_short, results, labels, target_snr_print, xlabel, ylabel, title, directory):\n",
    "    data = [[np.mean(results[method][scope][name_short]) for method in results.keys()] for scope in target_snr_print + ['all']]\n",
    "    plt.xticks(range(len(data[0])), labels)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.title(title)\n",
    "    width = 0.12\n",
    "\n",
    "    for i in range(len(target_snr_print) + 1):\n",
    "        plt.bar(np.arange(len(data[i])) + i * width, data[i], width=width)\n",
    "    plt.legend(target_snr_print + ['all'])\n",
    "    \n",
    "    plt.savefig(os.path.join(directory, name_short + '.png'), format='png')\n",
    "    plt.show()\n",
    "\n",
    "def save_results(results, config):\n",
    "\n",
    "    if not os.path.exists('./results'):\n",
    "        os.mkdir('./results')\n",
    "\n",
    "    # run_name = str(len(os.listdir('./results')))\n",
    "    # working_dir = os.path.join('./results', run_name)\n",
    "    # working_dir = os.mkdir(working_dir)\n",
    "\n",
    "    working_dir = os.path.join('./results', '2')\n",
    "\n",
    "    results_print = {method: {scope: {evaluation: {mean: float(np.mean(values)), sd: float(np.std(values))} for evaluation, values in eval_method.items()} for scope, eval_method in method_value.items()} for method, method_value in results.items()}\n",
    "    with open(os.path.join(working_dir, 'results.json'), 'w+') as output_file:\n",
    "        json.dump(results_print, output_file, indent=4)\n",
    "\n",
    "    plot_result_bar('snr_imp', results, config['labels'], config['target_snr_print'], config['xlabel'], 'SNR Improvement (dB)', 'Mean SNR Improvement', working_dir)\n",
    "    plot_result_bar('mse', results, config['labels'], config['target_snr_print'], config['xlabel'], 'MSE', 'Mean MSE', working_dir)\n",
    "    plot_result_bar('rmse', results, config['labels'], config['target_snr_print'], config['xlabel'], 'RMSE', 'Mean RMSE', working_dir)\n",
    "    plot_result_bar('mae', results, config['labels'], config['target_snr_print'], config['xlabel'], 'MAE', 'Mean MAE', working_dir)\n",
    "    plot_result_bar('psnr', results, config['labels'], config['target_snr_print'], config['xlabel'], 'PSNR', 'Mean PSNR', working_dir)\n",
    "    plot_result_bar('xcorr', results, config['labels'], config['target_snr_print'], config['xlabel'], 'Cross Correlation', 'Mean Cross Correlation', working_dir)\n",
    "    plot_result_bar('pcorr', results, config['labels'], config['target_snr_print'], config['xlabel'], 'Pearson Correlation Coefficient', 'Mean Pearson Correlation Coefficient', working_dir)\n",
    "    plot_result_bar('prd', results, config['labels'], config['target_snr_print'], config['xlabel'], 'PRD (%)', 'Mean PRD', working_dir)\n",
    "\n",
    "    # CPU Consumption\n",
    "    data = [np.mean(results[method]['all']['cpu_time']) * 1000 for method in results.keys()]\n",
    "\n",
    "    plt.xticks(range(len(data)), config['labels'])\n",
    "    plt.xlabel('Denoising Method')\n",
    "    plt.ylabel('CPU Time (ms)')\n",
    "    plt.title('Mean CPU Time')\n",
    "\n",
    "    plt.bar(np.arange(len(data)), data)\n",
    "    \n",
    "    plt.savefig(os.path.join(working_dir, 'cpu.png'))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab33828",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(config):\n",
    "    \n",
    "    with torch.no_grad():\n",
    "\n",
    "        ae1 = DeNoise2(layer_size=256).to(device)\n",
    "        ae1.load_state_dict(torch.load(os.path.join(model_directory, config['models'][0])))\n",
    "        ae1.eval()\n",
    "\n",
    "        ae2 = DeNoise1(layer_size=256).to(device)\n",
    "        ae2.load_state_dict(torch.load(os.path.join(model_directory, config['models'][1])))\n",
    "        ae2.eval()\n",
    "\n",
    "        ae3 = DeNoise2(layer_size=256).to(device)\n",
    "        ae3.load_state_dict(torch.load(os.path.join(model_directory, config['models'][2])))\n",
    "        ae3.eval()\n",
    "\n",
    "        ae4 = DeNoise2(layer_size=256).to(device)\n",
    "        ae4.load_state_dict(torch.load(os.path.join(model_directory, config['models'][3])))\n",
    "        ae4.eval()\n",
    "\n",
    "        results = {}\n",
    "\n",
    "        for method in config['methods']:\n",
    "            \n",
    "            results[method] = {}\n",
    "            for target in test_target_snr_dbs + ['all']:\n",
    "                results[method][target] = {\n",
    "                    'result': [],\n",
    "                    'snr_imp': [],\n",
    "                    'mse': [],\n",
    "                    'rmse': [],\n",
    "                    'mae': [],\n",
    "                    'psnr': [],\n",
    "                    'xcorr': [],\n",
    "                    'pcorr': [],\n",
    "                    'prd': [],\n",
    "                    'cpu_time': []\n",
    "                }\n",
    "            i = 0\n",
    "            for i, (noise, clean) in enumerate(test_dataset):\n",
    "\n",
    "                cpu_time = 0\n",
    "\n",
    "                if method == 'AE1':\n",
    "                    \n",
    "                    noise = noise.reshape(-1, 1, segment_size_samples).to(device, dtype=torch.float)\n",
    "\n",
    "                    cpu_time_start = time.process_time()\n",
    "                    predicted = ae1(noise)\n",
    "                    cpu_time_stop = time.process_time()\n",
    "                    cpu_time = cpu_time_stop - cpu_time_start\n",
    "\n",
    "                    noise = noise.to('cpu').reshape(segment_size_samples).numpy()\n",
    "                    predicted = predicted.to('cpu').reshape(segment_size_samples).numpy()\n",
    "                elif method == 'AE2':\n",
    "                    noise = noise.reshape(-1, 1, segment_size_samples).to(device, dtype=torch.float)\n",
    "\n",
    "                    cpu_time_start = time.process_time()\n",
    "                    predicted = ae2(noise)\n",
    "                    cpu_time_stop = time.process_time()\n",
    "                    cpu_time = cpu_time_stop - cpu_time_start\n",
    "\n",
    "                    noise = noise.to('cpu').reshape(segment_size_samples).numpy()\n",
    "                    predicted = predicted.to('cpu').reshape(segment_size_samples).numpy()\n",
    "                elif method == 'WD':\n",
    "                    noise = noise.numpy()\n",
    "\n",
    "                    cpu_time_start = time.process_time()\n",
    "                    predicted = denoise_wavelet(noise, method='BayesShrink', mode='soft', wavelet_levels=1, wavelet='sym8', rescale_sigma='True')\n",
    "                    cpu_time_stop = time.process_time()\n",
    "                    cpu_time = cpu_time_stop - cpu_time_start\n",
    "                elif method == 'AE3':\n",
    "                    # noise = noise.numpy()\n",
    "\n",
    "                    # cpu_time_start = time.process_time()\n",
    "                    # predicted = denoise_wavelet(noise, method='BayesShrink', mode='soft', wavelet_levels=1, wavelet='sym8', rescale_sigma='True')\n",
    "                    # noise = torch.from_numpy(predicted)\n",
    "                    # noise = noise.reshape(-1, 1, segment_size_samples).to(device)\n",
    "                    # predicted = ae1(noise)\n",
    "                    # cpu_time_stop = time.process_time()\n",
    "                    # cpu_time = cpu_time_stop - cpu_time_start\n",
    "\n",
    "                    # noise = noise.to('cpu').reshape(segment_size_samples).numpy()\n",
    "                    # predicted = predicted.to('cpu').reshape(segment_size_samples).numpy()\n",
    "\n",
    "                    noise = noise.reshape(-1, 1, segment_size_samples).to(device, dtype=torch.float)\n",
    "\n",
    "                    cpu_time_start = time.process_time()\n",
    "                    predicted = ae3(noise)\n",
    "                    cpu_time_stop = time.process_time()\n",
    "                    cpu_time = cpu_time_stop - cpu_time_start\n",
    "\n",
    "                    noise = noise.to('cpu').reshape(segment_size_samples).numpy()\n",
    "                    predicted = predicted.to('cpu').reshape(segment_size_samples).numpy()\n",
    "                elif method == 'AE4':\n",
    "                    noise = noise.reshape(-1, 1, segment_size_samples).to(device, dtype=torch.float)\n",
    "\n",
    "                    cpu_time_start = time.process_time()\n",
    "                    predicted = ae4(noise)\n",
    "                    cpu_time_stop = time.process_time()\n",
    "                    cpu_time = cpu_time_stop - cpu_time_start\n",
    "\n",
    "                    noise = noise.to('cpu').reshape(segment_size_samples).numpy()\n",
    "                    predicted = predicted.to('cpu').reshape(segment_size_samples).numpy()\n",
    "                else:\n",
    "                    break\n",
    "\n",
    "                clean = clean.numpy()\n",
    "                noise_snr = denormalize(noise, test_dataset.dataset.min_val, test_dataset.dataset.max_val)\n",
    "                predicted_snr = denormalize(predicted, test_dataset.dataset.min_val, test_dataset.dataset.max_val)\n",
    "\n",
    "                snr_data = snr(clean, noise_snr)\n",
    "                for target in test_target_snr_dbs + ['all']:\n",
    "                    if (str(target) == 'all') or (snr_data > (target - 0.8) and snr_data < (target + 0.8)):\n",
    "                        i += 1\n",
    "                        results[method][target]['result'].append(predicted)\n",
    "                        results[method][target]['snr_imp'].append([snr(clean, predicted_snr) - snr_data])\n",
    "                        results[method][target]['mse'].append([mse(clean, predicted)])\n",
    "                        results[method][target]['rmse'].append([rmse(clean, predicted)])\n",
    "                        results[method][target]['mae'].append([mae(clean, predicted)])\n",
    "                        # results[method][target]['psnr'].append([psnr(clean, predicted)])\n",
    "                        if config['mode'] == 1 and method == 'AE1':\n",
    "                            results[method][target]['xcorr'].append([xcorr(clean, predicted)])\n",
    "                            results[method][target]['pcorr'].append([pcorr(clean, predicted)])\n",
    "                        elif config['mode'] == 1 and method in ['AE1', 'AE3']:\n",
    "                            results[method][target]['xcorr'].append([xcorr(bandpass(clean), bandpass(predicted))])\n",
    "                            results[method][target]['pcorr'].append([pcorr(bandpass(clean), bandpass(predicted))])\n",
    "                        else:\n",
    "                            results[method][target]['xcorr'].append([xcorr(bandpass(clean), bandpass(predicted))])\n",
    "                            results[method][target]['pcorr'].append([pcorr(bandpass(clean), bandpass(predicted))])\n",
    "                        results[method][target]['prd'].append([prd(clean, predicted)])\n",
    "                        results[method][target]['cpu_time'].append(cpu_time)\n",
    "            \n",
    "            print(i)\n",
    "            value = 'all'\n",
    "            print('*** ' + method + ' ***')\n",
    "            print(len(results[method][value]['result']))\n",
    "            print('SNR IMP ' + str(np.mean(results[method][value]['snr_imp'])))\n",
    "            print('RMSE ' + str(np.mean(results[method][value]['rmse'])))\n",
    "            print('PRD ' + str(np.mean(results[method][value]['prd'])))\n",
    "            print('CPU TIME ' + str(np.mean(results[method][value]['cpu_time'])))\n",
    "            print()\n",
    "\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3266b49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing is done with a different set of target signal-to-noise ratios. Those are set here.\n",
    "train_dataset.dataset.add_noise(test_target_snr_dbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fbe20c1",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [19], line 30\u001b[0m\n\u001b[1;32m     20\u001b[0m config2 \u001b[39m=\u001b[39m {\n\u001b[1;32m     21\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mmode\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m0\u001b[39m,\n\u001b[1;32m     22\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mmethods\u001b[39m\u001b[39m'\u001b[39m: [\u001b[39m'\u001b[39m\u001b[39mAE1\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mAE2\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mWD\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mxlabel\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39mDenoising Method\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m     27\u001b[0m }\n\u001b[1;32m     29\u001b[0m \u001b[39m# 10 --> old, 10_3 --> newest\u001b[39;00m\n\u001b[0;32m---> 30\u001b[0m results \u001b[39m=\u001b[39m test(config2)\n\u001b[1;32m     31\u001b[0m save_results(results, config2)\n",
      "Cell \u001b[0;32mIn [17], line 50\u001b[0m, in \u001b[0;36mtest\u001b[0;34m(config)\u001b[0m\n\u001b[1;32m     47\u001b[0m noise \u001b[39m=\u001b[39m noise\u001b[39m.\u001b[39mreshape(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m, segment_size_samples)\u001b[39m.\u001b[39mto(device, dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mfloat)\n\u001b[1;32m     49\u001b[0m cpu_time_start \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mprocess_time()\n\u001b[0;32m---> 50\u001b[0m predicted \u001b[39m=\u001b[39m ae1(noise)\n\u001b[1;32m     51\u001b[0m cpu_time_stop \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mprocess_time()\n\u001b[1;32m     52\u001b[0m cpu_time \u001b[39m=\u001b[39m cpu_time_stop \u001b[39m-\u001b[39m cpu_time_start\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/thesis-project-iJTh5vgr/lib/python3.10/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn [8], line 43\u001b[0m, in \u001b[0;36mDeNoise2.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[1;32m     42\u001b[0m     encoded \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencoder(x)\n\u001b[0;32m---> 43\u001b[0m     decoded \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdecoder(encoded)\n\u001b[1;32m     44\u001b[0m     \u001b[39mreturn\u001b[39;00m decoded\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/thesis-project-iJTh5vgr/lib/python3.10/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/thesis-project-iJTh5vgr/lib/python3.10/site-packages/torch/nn/modules/container.py:204\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    203\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 204\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    205\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/thesis-project-iJTh5vgr/lib/python3.10/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/thesis-project-iJTh5vgr/lib/python3.10/site-packages/torch/nn/modules/conv.py:801\u001b[0m, in \u001b[0;36mConvTranspose1d.forward\u001b[0;34m(self, input, output_size)\u001b[0m\n\u001b[1;32m    797\u001b[0m num_spatial_dims \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    798\u001b[0m output_padding \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output_padding(\n\u001b[1;32m    799\u001b[0m     \u001b[39minput\u001b[39m, output_size, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkernel_size,  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m    800\u001b[0m     num_spatial_dims, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation)  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m--> 801\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv_transpose1d(\n\u001b[1;32m    802\u001b[0m     \u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding,\n\u001b[1;32m    803\u001b[0m     output_padding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# The config describes, which parameters should be tested.\n",
    "config0 = {\n",
    "    'mode': 1,\n",
    "    'methods': ['AE1', 'AE2', 'AE3', 'AE4'], #, 'WD']# , 'AE1+WD']\n",
    "    'models': ['new/model_2.pth', 'old/normal_full/model_2_1024_relu_extended_10_3.pth', 'old/normal_full/model_2_1024_relu_extended_10_3.pth', 'old/normal_full/model_2_1024_relu_extended_20.pth'],\n",
    "    'labels': ['Training Data', 'Results', 'Training Data + Results', 'No Usage'],\n",
    "    'target_snr_print': [-1, 0, 1, 3, 8], # [-1, 0, 0.5, 1, 3, 5, 8]\n",
    "    'xlabel': 'Bandpass Filter Usage'\n",
    "}\n",
    "\n",
    "config1 = {\n",
    "    'mode': 0,\n",
    "    'methods': ['AE1', 'AE2', 'AE3', 'AE4'], #, 'WD']# , 'AE1+WD']\n",
    "    'models': ['normal_full/model_2_1024_relu_simple.pth', 'normal_full/model_2_1024_relu_extended_5.pth', 'normal_full/model_2_1024_relu_extended_10_3.pth', 'normal_full/model_2_1024_relu_extended_20.pth'],\n",
    "    'labels': ['1', '2', '3', '4'],\n",
    "    'target_snr_print': [-1, 0, 1, 3, 8], # [-1, 0, 0.5, 1, 3, 5, 8]\n",
    "    'xlabel': 'Noise Distribution'\n",
    "}\n",
    "\n",
    "config2 = {\n",
    "    'mode': 0,\n",
    "    'methods': ['AE1', 'AE2', 'WD'],\n",
    "    'models': ['model_2.pth', 'old/normal_full/model_1_1024_relu_extended_10.pth', 'old/normal_full/model_2_1024_relu_extended_10.pth', 'old/normal_full/model_2_1024_relu_extended_20.pth'],\n",
    "    'labels': ['AE1', 'AE2', 'WD'],\n",
    "    'target_snr_print': [-1, 0, 1, 3, 8], # [-1, 0, 0.5, 1, 3, 5, 8]\n",
    "    'xlabel': 'Denoising Method'\n",
    "}\n",
    "\n",
    "# 10 --> old, 10_3 --> newest\n",
    "results = test(config2)\n",
    "save_results(results, config2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bc3d34b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5594\n",
      "tensor([-0.3050, -0.3445, -0.2872,  ..., -0.1195, -0.1615, -0.1974],\n",
      "       dtype=torch.float64)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for *: 'NoneType' and 'float'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 28\u001b[0m\n\u001b[1;32m     25\u001b[0m noise \u001b[39m=\u001b[39m noise\u001b[39m.\u001b[39mto(\u001b[39m'\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m.\u001b[39mreshape(segment_size_samples)\u001b[39m.\u001b[39mnumpy()\n\u001b[1;32m     26\u001b[0m predicted2 \u001b[39m=\u001b[39m denoise_wavelet(noise, method\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mBayesShrink\u001b[39m\u001b[39m'\u001b[39m, mode\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39msoft\u001b[39m\u001b[39m'\u001b[39m, wavelet_levels\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, wavelet\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39msym8\u001b[39m\u001b[39m'\u001b[39m, rescale_sigma\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mTrue\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> 28\u001b[0m noise_snr \u001b[39m=\u001b[39m denormalize(noise, test_dataset\u001b[39m.\u001b[39;49mdataset\u001b[39m.\u001b[39;49mmin_val, test_dataset\u001b[39m.\u001b[39;49mdataset\u001b[39m.\u001b[39;49mmax_val)\n\u001b[1;32m     29\u001b[0m \u001b[39m# predicted_snr = denormalize(predicted, test_dataset.dataset.min_val, test_dataset.dataset.max_val)\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[39m# predicted2_snr = denormalize(predicted2, test_dataset.dataset.min_val, test_dataset.dataset.max_val)\u001b[39;00m\n\u001b[1;32m     32\u001b[0m from_val \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
      "Cell \u001b[0;32mIn[25], line 17\u001b[0m, in \u001b[0;36mdenormalize\u001b[0;34m(data, min_val, max_val)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdenormalize\u001b[39m(data, min_val, max_val):\n\u001b[0;32m---> 17\u001b[0m     data_denorm \u001b[39m=\u001b[39m (max_val \u001b[39m*\u001b[39;49m data \u001b[39m+\u001b[39m max_val \u001b[39m-\u001b[39m data \u001b[39m*\u001b[39m min_val \u001b[39m+\u001b[39m min_val) \u001b[39m/\u001b[39m \u001b[39m2\u001b[39m\n\u001b[1;32m     18\u001b[0m     \u001b[39mreturn\u001b[39;00m data_denorm\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for *: 'NoneType' and 'float'"
     ]
    }
   ],
   "source": [
    "model1 = DeNoise2(layer_size=128).to(device)\n",
    "model1.load_state_dict(torch.load(os.path.join(model_directory, 'model_2.pth')))\n",
    "\n",
    "model2 = DeNoise2(layer_size=128).to(device)\n",
    "# model2.load_state_dict(torch.load(os.path.join(model_directory, 'loss_2_1024_relu_extended_5.pth')))\n",
    "\n",
    "model1.eval()\n",
    "model2.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    \n",
    "    i = random.choice(range(0, len(test_dataset)))\n",
    "    print(i)\n",
    "\n",
    "    noise = test_dataset[i][0]\n",
    "    clean = test_dataset[i][1]\n",
    "\n",
    "    clean = clean.reshape(-1, 1, segment_size_samples).to(device, dtype=torch.float)\n",
    "    noise = noise.reshape(-1, 1, segment_size_samples).to(device, dtype=torch.float)\n",
    "\n",
    "    predicted = model1(noise).to('cpu').reshape(segment_size_samples).numpy()\n",
    "    predicted2 = model2(noise).to('cpu').reshape(segment_size_samples).numpy()\n",
    "    clean = clean.to('cpu').reshape(segment_size_samples).numpy()\n",
    "    noise = noise.to('cpu').reshape(segment_size_samples).numpy()\n",
    "    predicted2 = denoise_wavelet(noise, method='BayesShrink', mode='soft', wavelet_levels=1, wavelet='sym8', rescale_sigma='True')\n",
    "\n",
    "    # noise_snr = denormalize(noise, test_dataset.dataset.min_val, test_dataset.dataset.max_val)\n",
    "    # predicted_snr = denormalize(predicted, test_dataset.dataset.min_val, test_dataset.dataset.max_val)\n",
    "    # predicted2_snr = denormalize(predicted2, test_dataset.dataset.min_val, test_dataset.dataset.max_val)\n",
    "\n",
    "    from_val = 0\n",
    "    to_val = 1024\n",
    "\n",
    "    print(mse(clean, noise))\n",
    "    print(mse(clean, predicted))\n",
    "    print()\n",
    "\n",
    "    print(mae(clean, noise))\n",
    "    print(mae(clean, predicted))\n",
    "    print()\n",
    "\n",
    "    print(snr(clean, noise_snr))\n",
    "    print(snr(clean, predicted_snr))\n",
    "    print(snr(clean, predicted2_snr))\n",
    "    print()\n",
    "\n",
    "    print(psnr(clean, noise))\n",
    "    print(psnr(clean, predicted))\n",
    "    print()\n",
    "\n",
    "    print(pcorr(clean, noise))\n",
    "    print(pcorr(clean, predicted))\n",
    "    print()\n",
    "    \n",
    "    time_from = 0\n",
    "    time_to = 1024\n",
    "\n",
    "    plt.plot(range(time_to)[time_from:time_to], noise[time_from:time_to])\n",
    "    plt.show()\n",
    "    plt.plot(range(time_to)[time_from:time_to], clean[time_from:time_to])\n",
    "    plt.show()\n",
    "    plt.plot(range(time_to)[time_from:time_to], predicted[time_from:time_to])\n",
    "    plt.show()\n",
    "    plt.plot(range(time_to)[time_from:time_to], predicted2[time_from:time_to])\n",
    "    plt.show()\n",
    "\n",
    "    torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis-project-i_Sg-Li3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "e6717f947e3cb42ac9683eac40a7d814e21ca3f0fa83f7d2ca8c93372cd6a329"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
