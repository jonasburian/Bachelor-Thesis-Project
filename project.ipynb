{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd2b25d5",
   "metadata": {},
   "source": [
    "# Thesis Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "157ff5a7",
   "metadata": {},
   "source": [
    "## Requirements and Imports\n",
    "\n",
    "All requirements in this project are managed by `Pipenv` and are denoted in the `Pipfile`, which can be found in the same directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b4b0800",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic imports\n",
    "import os\n",
    "import re\n",
    "import glob\n",
    "import wfdb\n",
    "import time\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from wfdb import processing\n",
    "from functools import partial\n",
    "\n",
    "# PyTorch related imports\n",
    "import torch\n",
    "import torchinfo\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# RayTune related imports\n",
    "from ray import tune, put, get, ray\n",
    "from ray.tune import CLIReporter\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "\n",
    "# Scipy and Sklearn related imports\n",
    "from scipy import signal, stats\n",
    "from statsmodels.tsa.stattools import ccf\n",
    "from skimage.restoration import denoise_wavelet\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0e8cb7b9",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "The following code cell can be used to configure certain aspects of the project regarding random number generation, graphics card utilization, model and data loading, noise models and training.\n",
    "To specify offsets (for instance for the sampling rate or the segment size), please refer to the official [pandas documentation](https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#offset-aliases)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c145768a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a random seed for pytorch (always split the data the same way), for the random package and for numpy. Required for reproducability.\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "\n",
    "# If a GPU (Cuda) is available, it will be used to train and test the machine learning models.\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# The directory for saving and loading the trained models.\n",
    "model_directory = './models/'\n",
    "\n",
    "# Here, some basic settings for the datasets and are set.\n",
    "data_directory = './data/'\n",
    "sampling_rate = 100 # Hz\n",
    "window_size = 512\n",
    "step_size = 64\n",
    "\n",
    "train_split = 0.8\n",
    "val_split = 0.2\n",
    "\n",
    "# The target noise SNR values for training and testing.\n",
    "train_target_snr_dbs = [-2.5, 0, 2.5, 17.5, 20, 22.5] # dB\n",
    "test_target_snr_dbs =  [-1, 0, 2, 5, 7] # dB\n",
    "\n",
    "# Number of epochs for training.\n",
    "num_epochs = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fbeb9e6",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "This is a utility class which is used to manage the required data and for adding and generating noise to the data samples. It inherits from the PyTorch `Dataset` class, which provides tools like splitting the data into train, validation and test subsets or using it in dataloaders to efficiently access the data in batches while training and testing. The dataset for this experiment coprises the [CEBS](https://physionet.org/content/cebsdb/1.0.0/) dataset, the [IEEE](https://ieee-dataport.org/documents/mechanocardiograms-ecg-reference) dataset and another dataset, called [D2](https://zenodo.org/record/5279448). Either SCG and ECG samples can be used as x and y values or SCG and noisy SCG samples. The data from the denoted datasets will be loaded directly when initialising an object of the class. Each dataset will be imported, depending on its specific characteristics, the schemas will be normalized, the dataset will be resampled and each dataset will be splitted into windows with a size of `segment_size_samples` and an offset of 128. Subsequelty, all datasets will be combined. Noise will only be added if the y samples are from an SCG signal. However, initially no noise will be added to the data, i.e. the clean and noisy data will be the same in the beginning. This is done so that training and testing can be done with different noise levels. The noise generated is gaussian white noise and/or from a second noise model that which focusses on motion noise. The two noise models can be used independently or together, with a certain probalility in generating WGN. The motion focussed noise model apopts noise data from a dataset which comprises [data from a chest-worn accelerometer](https://archive.ics.uci.edu/ml/datasets/Activity+Recognition+from+Single+Chest-Mounted+Accelerometer) while doing 7 different activities. The gravity component will be removed from the data as it is already present in the SCG datasets. To model the noise, `segment_size_samples` long consequtive samples will be extracted and added to the y-samples. Please note that the code for generating the WGN noise was adopted from [this](https://stackoverflow.com/a/53688043) example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46e9a7aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "A method to normalize the input data between -1 and 1. Returns the minimum and maximum values of the original signal aswell for later denormalization.\n",
    ":param data: The data that should be normalized.\n",
    "'''\n",
    "def normalize(data):\n",
    "    # If the data consists of several arrays, concatenate it to find the minimum and maximum.\n",
    "    data_concat = np.concatenate(data) if data[0].ndim == 1 else data\n",
    "    min_val = np.min(data_concat)\n",
    "    max_val = np.max(data_concat)\n",
    "    data_norm = 2 * (data - min_val) / (max_val - min_val) - 1\n",
    "    return data_norm, min_val, max_val\n",
    "\n",
    "'''\n",
    "Denormalizes the input data to its original form, given the minimum and maximum values of the original signal.\n",
    ":param data: The data that should be normalized.\n",
    ":param min_val: The minimum value of the original, not normalized data.\n",
    ":param max_val: The maximum value of the original, not normalized data.\n",
    "'''\n",
    "def denormalize(data, min_val, max_val):\n",
    "    data_denorm = (max_val * data + max_val - data * min_val + min_val) / 2\n",
    "    return data_denorm\n",
    "\n",
    "'''\n",
    "A butter bandpass filter for the input signal.\n",
    ":param input_signal: The signal on which the filter should be applied to.\n",
    ":param order: The order of the filter.\n",
    ":param fs: The frequency space.\n",
    ":param lowcut: The highcut of the filter.\n",
    ":param highcut: The lowcut of the filter.\n",
    "'''\n",
    "def bandpass(input_signal, order=4, fs=100.0, lowcut=5.0, highcut=30.0):\n",
    "    nyq = 0.5 * fs\n",
    "    low = lowcut / nyq\n",
    "    high = highcut / nyq\n",
    "\n",
    "    b, a, = signal.butter(order, [low, high], 'bandpass', analog=False)\n",
    "    y = signal.filtfilt(b, a, input_signal, axis=0)\n",
    "\n",
    "    return y\n",
    "\n",
    "'''\n",
    "A method to filter out peaks of a given input signal by comparing the z-score of the input sample to a threshhold value. \n",
    ":param input_signal: The signal on which the filter should be applied to.\n",
    ":param z_score_th: Every sample with a z-score above this threshold will be set to the mean of the signal.\n",
    "'''\n",
    "def filter_peaks(input_signal, z_score_th=7):\n",
    "    output_signal = input_signal.copy()\n",
    "    output_signal.loc[np.abs(stats.zscore(output_signal)) > z_score_th] = output_signal.mean()\n",
    "    return output_signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9c8d52a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SCGData(Dataset):\n",
    "\n",
    "    '''\n",
    "    A dataset class to manage all the different datasets being used in this project.\n",
    "\n",
    "    :param directory: The directory where the datasets (each in their own directory) are located.\n",
    "    :param datasets: A list of strings 'CEBS', 'D2' or 'IEEE' of the datasets that should be loaded.\n",
    "    :param transform: The transformation that will be applied to the data samples when they are accessed.\n",
    "    :param ecg: If true, the y_data samples will be ecg data and otherwise the noisy SCG samples.\n",
    "    :param noise: If true, noise may be added to the x samples by calling the add_noise method. Otherwise, calling this method will have no effects.\n",
    "    :param is_bandpass: If true, a bandpass filter will be applied to the noise samples after adding noise within the add_noise method.\n",
    "    '''\n",
    "    def __init__(self, directory, datasets, sampling_rate, window_size, step_size, transform=None, ecg=False, noise=True, is_bandpass=False):\n",
    "\n",
    "        self.directory = directory\n",
    "        self.datasets = datasets\n",
    "        self.sampling_rate = sampling_rate\n",
    "        self.window_size = window_size\n",
    "        self.step_size = step_size\n",
    "        self.transform = transform\n",
    "        self.ecg = ecg\n",
    "\n",
    "        self.noise = noise\n",
    "        self.data_motion_noise = None # Saves the data loaded from the motion dataset to later add motion noise.\n",
    "        self.is_bandpass = is_bandpass\n",
    "        \n",
    "        # The min/max values after normalizing the noise noisy x_data. Used for later denormalization to calculate the SNR.\n",
    "        self.min_val = None\n",
    "        self.max_val = None\n",
    "\n",
    "        # Load the motion noise data.\n",
    "        self.__load_motion_noise_data()\n",
    "\n",
    "        # Load and preprocess the requested datasets from `datasets`.\n",
    "        data = self.__load_datasets()\n",
    "        \n",
    "        # Groundtruth to later add noise to produce the x_data.\n",
    "        self.scg_clean = data.SCG.values\n",
    "        \n",
    "        # The y values are either ECG samples (when ecg=True) or SCG samples (when ecg=False). Noise will be added later.\n",
    "        if self.ecg:\n",
    "            self.x_data = data.SCG.values\n",
    "            self.y_data = data.ECG.values\n",
    "        else:\n",
    "            self.x_data = data.SCG.values\n",
    "            self.y_data = data.SCG.values\n",
    "\n",
    "        self.n_samples = data.shape[0]\n",
    "\n",
    "    '''\n",
    "    The function may be called to add noise to the x values when no ECG samples were loaded. The values will be randomly sampled from this list.\n",
    "\n",
    "    :param target_snr_dbs: A list of SNR values to be added with the WGN model. \n",
    "    :param noise_model: This parameter can either be 'WGN' for the White Gaussian Noise Model, 'MOTION' for the motion noise model or 'BOTH' for both noise models to be added to the dataset.\n",
    "    :param wgn_prob: Determines the probability with what the WGN model will be added to the dataset if 'BOTH' was chosen as the noise model.\n",
    "    '''\n",
    "    def add_noise(self, target_snr_dbs, noise_model='WGN', wgn_prob=0.33):\n",
    "\n",
    "        if self.noise:\n",
    "            if noise_model == 'WGN':\n",
    "                data_noise = np.array([self.__add_gaussian(inputs, target_snr_dbs) for inputs in self.scg_clean])\n",
    "            elif noise_model == 'MOTION':\n",
    "                data_noise = np.array([self.__add_motion(inputs) for inputs in self.scg_clean])\n",
    "            elif noise_model == 'BOTH':\n",
    "                data_noise = np.array([self.__add_gaussian(inputs, target_snr_dbs) if random.random() < wgn_prob else self.__add_motion(inputs) for inputs in self.scg_clean])\n",
    "\n",
    "            if self.is_bandpass:\n",
    "                data_noise = np.array([bandpass(inputs) for inputs in data_noise])\n",
    "\n",
    "            self.x_data, self.min_val, self.max_val = normalize(data_noise)\n",
    "\n",
    "    '''\n",
    "    A function to add motion noise to its inputs.\n",
    "\n",
    "    :param data: The data, to which the noise should be added.\n",
    "    '''\n",
    "    def __add_motion(self, data):\n",
    "        \n",
    "        # Randomly select `len(data)` consecutive samples from the processed noise dataset.\n",
    "        num_samples = len(data)\n",
    "        rows = range(self.data_motion_noise.shape[0])\n",
    "        index_start = random.randint(rows.start, rows.stop - num_samples)\n",
    "        noise = self.data_motion_noise.iloc[index_start:index_start + num_samples]\n",
    "        \n",
    "        # Only add 50 % of the noise to the data.\n",
    "        return data + 0.5 * noise\n",
    "\n",
    "    '''\n",
    "    A function to add WGN noise to its inputs.\n",
    "\n",
    "    :param data: The data, to which the noise should be added.\n",
    "    :param target_snr_dbs: A list of SNR values to be added. \n",
    "    '''\n",
    "    def __add_gaussian(self, data, target_snr_dbs):\n",
    "\n",
    "        target_snr_db = random.choice(target_snr_dbs)\n",
    "\n",
    "        data_avg_watts = np.mean(data ** 2)\n",
    "        data_avg_db = 10 * np.log10(data_avg_watts)\n",
    "\n",
    "        noise_avg_db = data_avg_db - target_snr_db\n",
    "        noise_avg_watts = 10 ** (noise_avg_db / 10)\n",
    "\n",
    "        mean_noise = 0\n",
    "        noise = np.random.normal(mean_noise, np.sqrt(noise_avg_watts), len(data))\n",
    "        \n",
    "        return data + noise\n",
    "\n",
    "    '''\n",
    "    Loads the motion noise dataset, upsamples and normalizes it.\n",
    "    '''\n",
    "    def __load_motion_noise_data(self):\n",
    "        data = pd.DataFrame()\n",
    "\n",
    "        for i in range(1, 16):\n",
    "            rel_path = os.path.join('NOISE_ACC', f'{i}.csv')\n",
    "            df = pd.read_csv(os.path.join(self.directory, rel_path), header=None, usecols=[3, 4], names=['Z', 'labels'])\n",
    "            \n",
    "            df_resample = pd.DataFrame()\n",
    "            frequency = 52\n",
    "\n",
    "            # Upsample the z-axis data, subtract the mean (gravity compoment), remove outliers and normalize it \n",
    "            df_resample['Z'] = processing.resample_sig(df['Z'], frequency, self.sampling_rate)[0]\n",
    "            df_resample['Z'] = df_resample['Z'] - df_resample['Z'].mean() # Remove the gravity component from the acceleration data\n",
    "            df_resample['Z'] = filter_peaks(df_resample['Z'], z_score_th=5)\n",
    "            df_resample['Z'], _, _ = normalize(df_resample['Z'])\n",
    "\n",
    "            # Upsample the labels, round them and prevent values larger than 7 and smaller than 1.\n",
    "            df_resample['labels'] = processing.resample_sig(df['labels'], frequency, self.sampling_rate)[0]\n",
    "            df_resample['labels'] = df_resample['labels'].round(decimals=0)\n",
    "            df_resample.loc[df_resample['labels'] > 7, 'labels'] = 7\n",
    "            df_resample.loc[df_resample['labels'] < 1, 'labels'] = 1\n",
    "\n",
    "            data = pd.concat((data, df_resample))\n",
    "\n",
    "        # The different activities in the dataset.\n",
    "            # 1: Working at Computer\n",
    "            # 2: Standing Up, Walking and Going up\\down stairs\n",
    "            # 3: Standing\n",
    "            # 4: Walking\n",
    "            # 5: Going Up\\Down Stairs\n",
    "            # 6: Walking and Talking with Someone\n",
    "            # 7: Talking while Standing\n",
    "\n",
    "        # Here it is possible to only allow certain activities in the noise dataset.\n",
    "        # self.data_motion_noise = data.loc[data['labels'] == 4, 'Z']\n",
    "        self.data_motion_noise = data['Z']\n",
    "\n",
    "    \n",
    "    '''\n",
    "    Loads one file of the CEBS dataset and processes it. This includes resampling, filtering and splitting into groups of `self.window_size` samples.\n",
    "\n",
    "    :param filename: The name of the specific file to be loaded.\n",
    "    '''\n",
    "    def __load_cebs(self, filename):\n",
    "        \n",
    "        # Using WFDB to import the files.\n",
    "        record = wfdb.rdsamp(filename)\n",
    "        data = record[0]\n",
    "        metadata = record[1]\n",
    "\n",
    "        frequency = metadata['fs']\n",
    "        column_names = metadata['sig_name']\n",
    "\n",
    "        data = pd.DataFrame(data, columns=column_names)\n",
    "        data.drop(['II', 'RESP'], axis=1, inplace=True)\n",
    "        data.rename(columns={'I': 'ECG'}, inplace=True)\n",
    "\n",
    "        # Resample the data into the desired sampling rate and bandpass filter the scg samples.\n",
    "        scg = processing.resample_sig(data['SCG'], frequency, self.sampling_rate)[0]\n",
    "        scg = bandpass(scg, order=4, fs=100.0, lowcut=5.0, highcut=30.0)\n",
    "        ecg = processing.resample_sig(data['ECG'], frequency, self.sampling_rate)[0]\n",
    "\n",
    "        data = pd.DataFrame({'SCG': scg, 'ECG': ecg})\n",
    "\n",
    "        # Filter out the peaks from the scg data\n",
    "        data['SCG'] = filter_peaks(data['SCG'], z_score_th=7)\n",
    "\n",
    "        # Split the data into groups with `self.window_size` and an offset of `self.step_size` samples.\n",
    "        data = pd.DataFrame([[x.ECG.to_numpy(), x.SCG.to_numpy()] for x in data.rolling(window=self.window_size, step=self.step_size) if x.shape[0] == self.window_size])\n",
    "        data.columns = ['ECG', 'SCG']\n",
    "\n",
    "        # Normalize the ECG and SCG data\n",
    "        data['ECG'], _, _ = normalize(data['ECG'])\n",
    "        data['SCG'], _, _ = normalize(data['SCG'])\n",
    "        \n",
    "        return data\n",
    "\n",
    "\n",
    "    '''\n",
    "    Loads one file of the D2 dataset and processes it. This includes resampling, filtering and splitting into groups of `self.window_size` samples.\n",
    "\n",
    "    :param filename: The name of the specific file to be loaded.\n",
    "    '''\n",
    "    def __load_d2(self, filename):\n",
    "\n",
    "        # Since the files are not structured the same, they have to be imported differently. The following code does that.\n",
    "        # Regex to identify files with specific names, as they are structured differently.\n",
    "        regex_up_1 = re.compile(r'./data/D2/UP-(((0|1)[0-9])|(20|21))-*') # Files named UP-[01-21]-Raw.csv\n",
    "        regex_up_2 = re.compile(r'./data/D2/UP-(22|23)-*') # Files named UP-[22-23]-Raw.csv\n",
    "\n",
    "        # Import the file depending on its structure.\n",
    "        if re.match(r'./data/D2/CP-*', filename):\n",
    "            data = pd.read_csv(filename, \n",
    "                    sep=',', \n",
    "                    header=1, \n",
    "                    skiprows=[2],\n",
    "                    usecols=['Shimmer_D0CD_ECG_LA-RA_24BIT_CAL', 'Shimmer_D0CD_Accel_LN_Z_CAL'], \n",
    "                    dtype={'Shimmer_D0CD_ECG_LA-RA_24BIT_CAL': 'float', 'Shimmer_D0CD_Accel_LN_Z_CAL': 'float'})\n",
    "            data.rename(columns={'Shimmer_D0CD_ECG_LA-RA_24BIT_CAL': 'ECG', 'Shimmer_D0CD_Accel_LN_Z_CAL': 'SCG'}, inplace=True)\n",
    "            frequency = 256\n",
    "        elif regex_up_1.match(filename):\n",
    "            data = pd.read_csv(filename, \n",
    "                    sep='\t', \n",
    "                    header=1, \n",
    "                    skiprows=[2],\n",
    "                    usecols=['ECG_ECG_LA-RA_24BIT_CAL', 'ECG_Accel_LN_Z_CAL'], \n",
    "                    dtype={'ECG_ECG_LA-RA_24BIT_CAL': 'float', 'ECG_Accel_LN_Z_CAL': 'float'})\n",
    "            data.rename(columns={'ECG_ECG_LA-RA_24BIT_CAL': 'ECG', 'ECG_Accel_LN_Z_CAL': 'SCG'}, inplace=True)\n",
    "            frequency = 256\n",
    "        elif regex_up_2.match(filename):\n",
    "            data = pd.read_csv(filename, \n",
    "                    sep=',', \n",
    "                    header=1, \n",
    "                    skiprows=[2],\n",
    "                    usecols=['ECG_ECG_LA-RA_24BIT_CAL', 'ECG_Accel_LN_Z_CAL'], \n",
    "                    dtype={'ECG_ECG_LA-RA_24BIT_CAL': 'float', 'ECG_Accel_LN_Z_CAL': 'float'})\n",
    "            data.rename(columns={'ECG_ECG_LA-RA_24BIT_CAL': 'ECG', 'ECG_Accel_LN_Z_CAL': 'SCG'}, inplace=True)\n",
    "            frequency = 512\n",
    "        elif re.match(r'./data/D2/UP-*', filename):\n",
    "            data = pd.read_csv(filename, \n",
    "                    sep=',', \n",
    "                    header=0, \n",
    "                    skiprows=[1],\n",
    "                    usecols=['ECG_ECG_LA-RA_24BIT_CAL', 'ECG_Accel_LN_Z_CAL'], \n",
    "                    dtype={'ECG_ECG_LA-RA_24BIT_CAL': 'float', 'ECG_Accel_LN_Z_CAL': 'float'})\n",
    "            data.rename(columns={'ECG_ECG_LA-RA_24BIT_CAL': 'ECG', 'ECG_Accel_LN_Z_CAL': 'SCG'}, inplace=True)            \n",
    "            frequency = 512\n",
    "        else:\n",
    "            return pd.DataFrame()\n",
    "\n",
    "        # Resample the data into the desired sampling rate and bandpass filter the scg samples.\n",
    "        scg = processing.resample_sig(data['SCG'], frequency, self.sampling_rate)[0]\n",
    "        scg = bandpass(scg, order=4, fs=100.0, lowcut=5.0, highcut=30.0)\n",
    "        ecg = processing.resample_sig(data['ECG'], frequency, self.sampling_rate)[0]\n",
    "        # ecg = bandpass(ecg, order=4, fs=100.0, lowcut=8.0, highcut=20.0)\n",
    "\n",
    "        data = pd.DataFrame({'SCG': scg, 'ECG': ecg})\n",
    "        \n",
    "        # Filter out the peaks from the scg data\n",
    "        data['SCG'] = filter_peaks(data['SCG'], z_score_th=7)\n",
    "        # data['ECG'] = filter_peaks(data['ECG'], z_score_th=7)\n",
    "\n",
    "        # Split the data into groups with `self.window_size` and an offset of `self.step_size` samples.\n",
    "        data = pd.DataFrame([[x.ECG.to_numpy(), x.SCG.to_numpy()] for x in data.rolling(window=self.window_size, step=self.step_size) if x.shape[0] == self.window_size and not np.isnan(x.SCG).any() and not np.isnan(x.ECG).any()])\n",
    "        data.columns = ['ECG', 'SCG']\n",
    "\n",
    "        # Normalize the ECG and SCG data\n",
    "        data['SCG'], _, _ = normalize(data['SCG'])\n",
    "        data['ECG'], _, _ = normalize(data['ECG'])\n",
    "\n",
    "        return data\n",
    "\n",
    "    \n",
    "    '''\n",
    "    Loads one file of the IEEE dataset and processes it. This includes resampling, filtering and splitting into groups of `self.window_size` samples.\n",
    "\n",
    "    :param filename: The name of the specific file to be loaded.\n",
    "    '''\n",
    "    def __load_ieee(self, filename):\n",
    "        \n",
    "        # Because of different headers in different files, a varying amount of rows has to be skipped.\n",
    "        if any(str(num) in filename for num in range(10,30)):\n",
    "            skiprows = 19\n",
    "        elif any(str(num) in filename for num in [8, 9]):\n",
    "            skiprows = 17\n",
    "        elif any(str(num) in filename for num in [2, 4, 5, 6, 7, 8]):\n",
    "            skiprows = 16\n",
    "        else:\n",
    "            skiprows = 15\n",
    "\n",
    "        data = pd.read_csv(filename, sep=' ', header=None, skiprows=skiprows, usecols=[0,3], names=['ECG', 'SCG'], dtype={'ECG': 'float', 'SCG': 'float'})\n",
    "        frequency = 800\n",
    "\n",
    "        # Resample the data into the desired sampling rate and bandpass filter the scg samples.\n",
    "        scg = processing.resample_sig(data['SCG'], frequency, self.sampling_rate)[0]\n",
    "        scg = bandpass(scg, order=4, fs=100.0, lowcut=5.0, highcut=30.0)\n",
    "        ecg = processing.resample_sig(data['ECG'], frequency, self.sampling_rate)[0]\n",
    "        # ecg = bandpass(ecg, order=4, fs=100.0, lowcut=8.0, highcut=20.0)\n",
    "\n",
    "        data = pd.DataFrame({'SCG': scg, 'ECG': ecg})\n",
    "        \n",
    "        # Filter out the peaks from the scg data\n",
    "        data['SCG'] = filter_peaks(data['SCG'], z_score_th=7)\n",
    "        # data['ECG'] = filter_peaks(data['ECG'], z_score_th=7)\n",
    "\n",
    "        # Split the data into groups with `self.window_size` and an offset of `self.step_size` samples.\n",
    "        data = pd.DataFrame([[x.ECG.to_numpy(), x.SCG.to_numpy()] for x in data.rolling(window=self.window_size, step=self.step_size) if x.shape[0] == self.window_size and not np.isnan(x.SCG).any() and not np.isnan(x.ECG).any()])\n",
    "        data.columns = ['ECG', 'SCG']\n",
    "        \n",
    "        # Normalize the ECG and SCG data\n",
    "        data['SCG'], _, _ = normalize(data['SCG'])\n",
    "        data['ECG'], _, _ = normalize(data['ECG'])\n",
    "\n",
    "        return data\n",
    "\n",
    "\n",
    "    '''\n",
    "    Loads the datasets denoted in the datasets parameter.\n",
    "    '''\n",
    "    def __load_datasets(self):\n",
    "\n",
    "        data = pd.Series(dtype='object')\n",
    "\n",
    "        # Loads the CEBS dataset from the 'CEBS' directory in the directory folder.\n",
    "        if 'CEBS' in self.datasets:\n",
    "            print('Loading CEBS')\n",
    "            \n",
    "            directory = os.path.join(self.directory, 'CEBS')\n",
    "            filenames = list(dict.fromkeys([x[:-4] for x in glob.glob(f'{directory}/*[0-9][0-9][0-9].*')]))\n",
    "            data_cebs = pd.concat((self.__load_cebs(filename) for filename in filenames), ignore_index=True)\n",
    "            data = pd.concat((data, data_cebs))\n",
    "            print(f'\\tLoaded {data_cebs.shape[0]} samples')\n",
    "\n",
    "\n",
    "        # Loads the D2 dataset from the 'D2' directory in the directory folder.\n",
    "        if 'D2' in self.datasets:\n",
    "            print('Loading D2')\n",
    "            \n",
    "            directory = os.path.join(self.directory, 'D2')\n",
    "            filenames = glob.glob(f'{directory}/*')\n",
    "            data_d2 = pd.concat((self.__load_d2(filename) for filename in filenames), ignore_index=True)\n",
    "            data = pd.concat((data, data_d2))\n",
    "            print(f'\\tLoaded {data_d2.shape[0]} samples')\n",
    "\n",
    "        # Loads the IEEE dataset from the 'IEEE' directory in the directory folder.\n",
    "        if 'IEEE' in self.datasets:\n",
    "            print('Loading IEEE')\n",
    "            \n",
    "            directory = os.path.join(self.directory, 'IEEE')\n",
    "            filenames = glob.glob(f'{directory}/*')\n",
    "            data_ieee = pd.concat((self.__load_ieee(filename) for filename in filenames), ignore_index=True)\n",
    "            data = pd.concat((data, data_ieee))\n",
    "            print(f'\\tLoaded {data_ieee.shape[0]} samples')\n",
    "        \n",
    "        print(f'\\nLoaded {data.shape[0]} samples in total')\n",
    "\n",
    "        return data\n",
    "\n",
    "    '''\n",
    "    Returns a sample with the specified index and applies the transformation, if it is set.\n",
    "\n",
    "    :param index: The index of the sample to be returned.\n",
    "    '''\n",
    "    def __getitem__(self, index):\n",
    "        sample = self.x_data[index].copy(), self.y_data[index].copy()\n",
    "\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "        \n",
    "        return sample\n",
    "    \n",
    "    '''\n",
    "    Returns the length of the dataset.\n",
    "    '''\n",
    "    def __len__(self):\n",
    "        return self.n_samples\n",
    "\n",
    "\n",
    "class ToTensor:\n",
    "\n",
    "    '''\n",
    "    Transformation class used to transform numpy arrays to PyTorch tensors.\n",
    "\n",
    "    :param sample: The sample from the dataset to be transformed.\n",
    "    '''\n",
    "    def __call__(self, sample):\n",
    "        inputs, targets = sample\n",
    "        return torch.from_numpy(inputs), torch.from_numpy(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1492b678",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Loads the data and returns randomly splitted test and train datasets with a predetermined train size.\n",
    "\n",
    "    :param directory: The directory where the datasets (each in their own directory) are located.\n",
    "    :param datasets: A list of strings 'CEBS', 'D2' or 'IEEE' of the datasets that should be loaded.\n",
    "    :param transform: The transformation that will be applied to the data samples when they are accessed.\n",
    "    :param ecg: If true, the y_data samples will be ecg data and otherwise the noisy SCG samples.\n",
    "    :param noise: If true, noise may be added to the x samples by calling the add_noise method. Otherwise, calling this method will have no effects.\n",
    "    :param is_bandpass: If true, a bandpass filter will be applied to the noise samples after adding noise within the add_noise method.\n",
    "'''\n",
    "def load_data(directory, datasets, sampling_rate, window_size, step_size, transform, ecg=False, noise=True, is_bandpass=False, train_prop=0.8):\n",
    "    dataset = SCGData(directory, datasets, sampling_rate, window_size, step_size, transform=transform, ecg=ecg, noise=noise, is_bandpass=is_bandpass)\n",
    "    train_size = int(train_prop * len(dataset))\n",
    "    test_size = len(dataset) - train_size\n",
    "    return torch.utils.data.random_split(dataset, [train_size, test_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "97834ec1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading CEBS\n",
      "\tLoaded 111514 samples\n",
      "Loading D2\n",
      "\tLoaded 69940 samples\n",
      "Loading IEEE\n",
      "\tLoaded 24073 samples\n",
      "\n",
      "Loaded 205527 samples in total\n"
     ]
    }
   ],
   "source": [
    "# Imports the dataset and splits it into a train and test subset.\n",
    "train_dataset, test_dataset = load_data(data_directory, ['CEBS', 'D2', 'IEEE'], sampling_rate, window_size, step_size, transform=ToTensor(), ecg=True, noise=True, is_bandpass=False, train_prop=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b837dfa1",
   "metadata": {},
   "source": [
    "## Machine Learning Models\n",
    "\n",
    "The next two code cells implement 2 fully convolutional denoising autoencoders. \n",
    "\n",
    "The first one consists of 4 conovlutional layers in the encoder and decoder plus another output layer in the decoder. A batch normalization layer follows after every convulutional layer, and elu was used as the activation function. The output layer is followed by the hyperbolic tangens function as the activation function. The kernel size is set to 7 with a stride of 1 while the number of filter `layer_size` halves with each convolutional layer in the encoder and doubles with each layer in the decoder. \n",
    "\n",
    "The second autoencoder is nearly equivalent to the first one. However, the stride of the second last and second layer of the encoder and decoder respectively is set to two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ba01cc41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Input Shape               Output Shape\n",
       "==========================================================================================\n",
       "DeNoise1                                 [32, 1, 512]              [32, 1, 512]\n",
       "├─Sequential: 1-1                        [32, 1, 512]              [32, 1, 488]\n",
       "│    └─Conv1d: 2-1                       [32, 1, 512]              [32, 128, 506]\n",
       "│    └─BatchNorm1d: 2-2                  [32, 128, 506]            [32, 128, 506]\n",
       "│    └─ELU: 2-3                          [32, 128, 506]            [32, 128, 506]\n",
       "│    └─Conv1d: 2-4                       [32, 128, 506]            [32, 64, 500]\n",
       "│    └─BatchNorm1d: 2-5                  [32, 64, 500]             [32, 64, 500]\n",
       "│    └─ELU: 2-6                          [32, 64, 500]             [32, 64, 500]\n",
       "│    └─Conv1d: 2-7                       [32, 64, 500]             [32, 32, 494]\n",
       "│    └─BatchNorm1d: 2-8                  [32, 32, 494]             [32, 32, 494]\n",
       "│    └─ELU: 2-9                          [32, 32, 494]             [32, 32, 494]\n",
       "│    └─Conv1d: 2-10                      [32, 32, 494]             [32, 1, 488]\n",
       "│    └─BatchNorm1d: 2-11                 [32, 1, 488]              [32, 1, 488]\n",
       "│    └─ELU: 2-12                         [32, 1, 488]              [32, 1, 488]\n",
       "├─Sequential: 1-2                        [32, 1, 488]              [32, 1, 512]\n",
       "│    └─ConvTranspose1d: 2-13             [32, 1, 488]              [32, 32, 494]\n",
       "│    └─BatchNorm1d: 2-14                 [32, 32, 494]             [32, 32, 494]\n",
       "│    └─ELU: 2-15                         [32, 32, 494]             [32, 32, 494]\n",
       "│    └─ConvTranspose1d: 2-16             [32, 32, 494]             [32, 64, 500]\n",
       "│    └─BatchNorm1d: 2-17                 [32, 64, 500]             [32, 64, 500]\n",
       "│    └─ELU: 2-18                         [32, 64, 500]             [32, 64, 500]\n",
       "│    └─ConvTranspose1d: 2-19             [32, 64, 500]             [32, 128, 506]\n",
       "│    └─BatchNorm1d: 2-20                 [32, 128, 506]            [32, 128, 506]\n",
       "│    └─ELU: 2-21                         [32, 128, 506]            [32, 128, 506]\n",
       "│    └─ConvTranspose1d: 2-22             [32, 128, 506]            [32, 1, 512]\n",
       "│    └─BatchNorm1d: 2-23                 [32, 1, 512]              [32, 1, 512]\n",
       "│    └─ELU: 2-24                         [32, 1, 512]              [32, 1, 512]\n",
       "│    └─Conv1d: 2-25                      [32, 1, 512]              [32, 1, 512]\n",
       "│    └─Tanh: 2-26                        [32, 1, 512]              [32, 1, 512]\n",
       "==========================================================================================\n",
       "Total params: 146,958\n",
       "Trainable params: 146,958\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 2.35\n",
       "==========================================================================================\n",
       "Input size (MB): 0.07\n",
       "Forward/backward pass size (MB): 115.92\n",
       "Params size (MB): 0.59\n",
       "Estimated Total Size (MB): 116.57\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class DeNoise1(nn.Module):\n",
    "    def __init__(self, layer_size=128):\n",
    "        super(DeNoise1, self).__init__()\n",
    "\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv1d(1, int(layer_size), 7, stride=1, padding=0),\n",
    "            nn.BatchNorm1d(int(layer_size)),\n",
    "            nn.ELU(),\n",
    "            nn.Conv1d(int(layer_size), int(layer_size/2), 7, stride=1, padding=0),\n",
    "            nn.BatchNorm1d(int(layer_size/2)),\n",
    "            nn.ELU(),\n",
    "            nn.Conv1d(int(layer_size/2), int(layer_size/4), 7, stride=1, padding=0),\n",
    "            nn.BatchNorm1d(int(layer_size/4)),\n",
    "            nn.ELU(),\n",
    "            nn.Conv1d(int(layer_size/4), 1, 7, stride=1, padding=0),\n",
    "            nn.BatchNorm1d(1),\n",
    "            nn.ELU()\n",
    "        )\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose1d(1, int(layer_size/4), 7, stride=1, padding=0),\n",
    "            nn.BatchNorm1d(int(layer_size/4)),\n",
    "            nn.ELU(),\n",
    "            nn.ConvTranspose1d(int(layer_size/4), int(layer_size/2), 7, stride=1, padding=0),\n",
    "            nn.BatchNorm1d(int(layer_size/2)),\n",
    "            nn.ELU(),\n",
    "            nn.ConvTranspose1d(int(layer_size/2), int(layer_size), 7, stride=1, padding=0),\n",
    "            nn.BatchNorm1d(int(layer_size)),\n",
    "            nn.ELU(),\n",
    "            nn.ConvTranspose1d(int(layer_size), 1, 7, stride=1, padding=0), \n",
    "            nn.BatchNorm1d(1),\n",
    "            nn.ELU(),\n",
    "            nn.Conv1d(1, 1, 7, stride=1, padding='same'),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded\n",
    "\n",
    "# Prints the structure of the Autoencoder\n",
    "torchinfo.summary(DeNoise1(), (32, 1, window_size), col_names=('input_size', 'output_size'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "031c1a44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Input Shape               Output Shape\n",
       "==========================================================================================\n",
       "DeNoise2                                 [32, 1, 512]              [32, 1, 512]\n",
       "├─Sequential: 1-1                        [32, 1, 512]              [32, 1, 241]\n",
       "│    └─Conv1d: 2-1                       [32, 1, 512]              [32, 128, 506]\n",
       "│    └─BatchNorm1d: 2-2                  [32, 128, 506]            [32, 128, 506]\n",
       "│    └─ELU: 2-3                          [32, 128, 506]            [32, 128, 506]\n",
       "│    └─Conv1d: 2-4                       [32, 128, 506]            [32, 64, 500]\n",
       "│    └─BatchNorm1d: 2-5                  [32, 64, 500]             [32, 64, 500]\n",
       "│    └─ELU: 2-6                          [32, 64, 500]             [32, 64, 500]\n",
       "│    └─Conv1d: 2-7                       [32, 64, 500]             [32, 32, 247]\n",
       "│    └─BatchNorm1d: 2-8                  [32, 32, 247]             [32, 32, 247]\n",
       "│    └─ELU: 2-9                          [32, 32, 247]             [32, 32, 247]\n",
       "│    └─Conv1d: 2-10                      [32, 32, 247]             [32, 1, 241]\n",
       "│    └─BatchNorm1d: 2-11                 [32, 1, 241]              [32, 1, 241]\n",
       "│    └─ELU: 2-12                         [32, 1, 241]              [32, 1, 241]\n",
       "├─Sequential: 1-2                        [32, 1, 241]              [32, 1, 512]\n",
       "│    └─ConvTranspose1d: 2-13             [32, 1, 241]              [32, 32, 247]\n",
       "│    └─BatchNorm1d: 2-14                 [32, 32, 247]             [32, 32, 247]\n",
       "│    └─ELU: 2-15                         [32, 32, 247]             [32, 32, 247]\n",
       "│    └─ConvTranspose1d: 2-16             [32, 32, 247]             [32, 64, 500]\n",
       "│    └─BatchNorm1d: 2-17                 [32, 64, 500]             [32, 64, 500]\n",
       "│    └─ELU: 2-18                         [32, 64, 500]             [32, 64, 500]\n",
       "│    └─ConvTranspose1d: 2-19             [32, 64, 500]             [32, 128, 506]\n",
       "│    └─BatchNorm1d: 2-20                 [32, 128, 506]            [32, 128, 506]\n",
       "│    └─ELU: 2-21                         [32, 128, 506]            [32, 128, 506]\n",
       "│    └─ConvTranspose1d: 2-22             [32, 128, 506]            [32, 1, 512]\n",
       "│    └─BatchNorm1d: 2-23                 [32, 1, 512]              [32, 1, 512]\n",
       "│    └─ELU: 2-24                         [32, 1, 512]              [32, 1, 512]\n",
       "│    └─Conv1d: 2-25                      [32, 1, 512]              [32, 1, 512]\n",
       "│    └─Tanh: 2-26                        [32, 1, 512]              [32, 1, 512]\n",
       "==========================================================================================\n",
       "Total params: 146,958\n",
       "Trainable params: 146,958\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 2.23\n",
       "==========================================================================================\n",
       "Input size (MB): 0.07\n",
       "Forward/backward pass size (MB): 107.70\n",
       "Params size (MB): 0.59\n",
       "Estimated Total Size (MB): 108.35\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class DeNoise2(nn.Module):\n",
    "    def __init__(self, layer_size=128):\n",
    "        super(DeNoise2, self).__init__()\n",
    "\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv1d(1, int(layer_size), 7, stride=1, padding=0),\n",
    "            nn.BatchNorm1d(int(layer_size)),\n",
    "            nn.ELU(),\n",
    "            nn.Conv1d(int(layer_size), int(layer_size/2), 7, stride=1, padding=0),\n",
    "            nn.BatchNorm1d(int(layer_size/2)),\n",
    "            nn.ELU(),\n",
    "            nn.Conv1d(int(layer_size/2), int(layer_size/4), 7, stride=2, padding=0),\n",
    "            nn.BatchNorm1d(int(layer_size/4)),\n",
    "            nn.ELU(),\n",
    "            nn.Conv1d(int(layer_size/4), 1, 7, stride=1, padding=0),\n",
    "            nn.BatchNorm1d(1),\n",
    "            nn.ELU()\n",
    "        )\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose1d(1, int(layer_size/4), 7, stride=1, padding=0),\n",
    "            nn.BatchNorm1d(int(layer_size/4)),\n",
    "            nn.ELU(),\n",
    "            nn.ConvTranspose1d(int(layer_size/4), int(layer_size/2), 7, stride=2, padding=0, output_padding=1),\n",
    "            nn.BatchNorm1d(int(layer_size/2)),\n",
    "            nn.ELU(),\n",
    "            nn.ConvTranspose1d(int(layer_size/2), int(layer_size), 7, stride=1, padding=0),\n",
    "            nn.BatchNorm1d(int(layer_size)),\n",
    "            nn.ELU(),\n",
    "            nn.ConvTranspose1d(int(layer_size), 1, 7, stride=1, padding=0), \n",
    "            nn.BatchNorm1d(1),\n",
    "            nn.ELU(),\n",
    "            nn.Conv1d(1, 1, 7, stride=1, padding='same'),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded\n",
    "\n",
    "# Prints the structure of the Autoencoder\n",
    "torchinfo.summary(DeNoise2(), (32, 1, window_size), col_names=('input_size', 'output_size'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc39d04",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "The following cells define the training procedure. Training will be done in a configurable number of epochs and with configurable batch sizes. The parameters, that are relevant for the training procedure will be denoted in a config, which will be passed to the training function via an argument. This includes the learning rate, weight decay for the Adam Optimizer, batch size and layer size of the autoencoder models. The MSE Loss will be used as a loss criterion, while the Adam optimizer is used to optimize the parameters of the model. The training data will be split into a training (80 %) and validation set (20 %) in order to further generelization capabilities of the model. To load the data, data loaders will be used. Those split the data into batches and also shuffle it for usage in training and validation. Moreover, the function includes some features for ray tune hyperparameter tuning like accessing the training data via the `data_id`. What is more, noise will be added to the y-samples in the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1c7816ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Method used for training the different machine learning models with a given config. \n",
    "\n",
    ":param config: The configuration for training as a dict. Includes the following parameters: \n",
    "                    - the learning rate (lr, float)\n",
    "                    - weight decay (wd, float)\n",
    "                    - batch size (batch_size, int)\n",
    "                    - layer size (layer_size, int)\n",
    ":param train_dataset: The train dataset.\n",
    ":param model_num: The number of the autoencoder (1 or 2).\n",
    ":param is_tune: If true, this function is used with the ray tune hyperparameter tuning framework.\n",
    ":param data_id: Used by ray tune to access the data from the ray tune object store.\n",
    ":param data_dir: The directory where the models should be saved.\n",
    "'''\n",
    "def train(config, train_dataset, model_num, is_tune=False, data_id=None, data_dir=None):\n",
    "\n",
    "    # Select and create the correct model, send it to the correct devide (cpu/cuda)\n",
    "    if model_num == 1:\n",
    "        model = DeNoise1(layer_size=config['layer_size'])\n",
    "    elif model_num == 2:\n",
    "        model = DeNoise2(layer_size=config['layer_size'])\n",
    "    model = model.to(device)\n",
    "\n",
    "    # Use MSE Loss as the loss function and the Adam optimizer for optimization.\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=config['lr'], weight_decay=config['wd'])\n",
    "\n",
    "    # For ray tune. Get the train dataset from the ray tune object store with the given data id.\n",
    "    if data_id:\n",
    "        train_dataset = get(data_id)\n",
    "\n",
    "    # Split the train dataset into a train and validation set.\n",
    "    val_size = int(val_split * len(train_dataset))\n",
    "    test_size = len(train_dataset) - val_size\n",
    "    train_dataset, val_dataset = torch.utils.data.random_split(train_dataset, [test_size, val_size])\n",
    "\n",
    "    # Create DataLoaders for the test and train dataset.\n",
    "    train_loader = DataLoader(dataset=train_dataset, batch_size=config['batch_size'], shuffle=True, num_workers=4, pin_memory=True)\n",
    "    val_loader = DataLoader(dataset=val_dataset, batch_size=config['batch_size'], shuffle=True, num_workers=4, pin_memory=True)\n",
    "\n",
    "    train_loss_values = []\n",
    "    val_loss_values = []\n",
    "    epoch_values = []\n",
    "\n",
    "    min_val_loss = np.inf\n",
    "\n",
    "    # Do training in several epochs\n",
    "    for epoch in range(num_epochs):\n",
    "        \n",
    "        train_loss = 0.0\n",
    "        for i, (inputs, lables) in enumerate(train_loader):\n",
    "            \n",
    "            # Send tensors to the desired device and reshape them to account for the input shape of the autoencoer.\n",
    "            inputs, lables = inputs.to(device, dtype=torch.float), lables.to(device, dtype=torch.float)\n",
    "            inputs, lables = inputs.view(-1, 1, window_size), lables.view(-1, 1, window_size)\n",
    "\n",
    "            # Calculate training loss and do backpropagation\n",
    "            optimizer.zero_grad()\n",
    "            output = model(inputs)\n",
    "            loss = criterion(output, lables)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "        \n",
    "        train_loss_values.append(train_loss)\n",
    "\n",
    "        val_loss = 0.0\n",
    "        for i, (inputs, lables) in enumerate(val_loader):\n",
    "\n",
    "            # Send tensors to the desired device and reshape them to account for the input shape of the autoencoer.\n",
    "            inputs, lables = inputs.to(device, dtype=torch.float), lables.to(device, dtype=torch.float)\n",
    "            inputs, lables = inputs.view(-1, 1, window_size), lables.view(-1, 1, window_size)\n",
    "\n",
    "            # Calculate validation loss\n",
    "            output = model(inputs)\n",
    "            loss = criterion(output, lables)\n",
    "            val_loss += loss.item()\n",
    "            \n",
    "        val_loss_values.append(val_loss)\n",
    "        epoch_values.append(epoch)\n",
    "\n",
    "        if is_tune:\n",
    "            tune.report(loss=(val_loss / len(val_loader)))\n",
    "        else:\n",
    "\n",
    "            # Print results and save the model if validation loss got lower,\n",
    "            print(f'epoch {epoch + 1} / {num_epochs}, train loss = {(train_loss / len(train_loader)):.10f}, val loss = {(val_loss / len(val_loader)):.10f}')\n",
    "            pd.DataFrame({'epoch': epoch_values,'train_loss': np.divide(train_loss_values, len(train_loader)), 'val_loss': np.divide(val_loss_values, len(val_loader))}).to_csv(f'./models/loss_{model_num}.csv') \n",
    "            \n",
    "            if min_val_loss > val_loss:\n",
    "                \n",
    "                print(f'\\tval loss decreased from {(min_val_loss/len(val_loader)):.10f} to {(val_loss/len(val_loader)):.10f}')\n",
    "                min_val_loss = val_loss\n",
    "                torch.save(model.state_dict(), os.path.join(model_directory, f'model_{model_num}.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c1549df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adds the correct noise levels for the training process.\n",
    "train_dataset.dataset.add_noise(train_target_snr_dbs, noise_model='WGN', wgn_prob=0.33)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c515a47d",
   "metadata": {},
   "source": [
    "{'lr': 0.00995997105429584, 'wd': 0, 'batch_size': 8, 'layer_size': 256} 0.004403432803698031\n",
    "{'lr': 0.0018729000345412963, 'wd': 0, 'batch_size': 8, 'layer_size': 256} 0.0004914292857526488\n",
    "{'lr': 0.0018437162360595998, 'wd': 0, 'batch_size': 8, 'layer_size': 128} 0.0007439919008643882\n",
    "{'lr': 0.0006948120282769452, 'wd': 0, 'batch_size': 16, 'layer_size': 128} 0.0013009571703150868\n",
    "\n",
    "{'lr': 0.005987474910461404, 'wd': 0, 'batch_size': 8, 'layer_size': 256} 0.08806516555488389 ecg\n",
    "{'lr': 0.0016753977246482176, 'wd': 0, 'batch_size': 8, 'layer_size': 256} 0.004527260314599609\n",
    "{'lr': 0.025283919654532777, 'wd': 0, 'batch_size': 8, 'layer_size': 256} 0.005443869859114262\n",
    "{'lr': 0.0013258026543339454, 'wd': 0, 'batch_size': 8, 'layer_size': 256} 0.00422055318578521\n",
    "{'lr': 0.006734006881666463, 'wd': 0, 'batch_size': 8, 'layer_size': 256} 0.0065393154912341675\n",
    "{'lr': 0.005862537900769703, 'wd': 0, 'batch_size': 64, 'layer_size': 256} 0.015984084544108244\n",
    "{'lr': 0.007377019703862149, 'wd': 0, 'batch_size': 32, 'layer_size': 256} 0.015106364335330386\n",
    "{'lr': 0.005862537900769703, 'wd': 0, 'batch_size': 16, 'layer_size': 256} 0.018258809970242595 w/o bandpass, 10\n",
    "{'lr': 0.026619018884890572, 'wd': 0, 'batch_size': 8, 'layer_size': 256} 0.09671060990187845 scg,ecg\n",
    "{'lr': 0.0017898461100052906, 'wd': 0, 'batch_size': 8, 'layer_size': 128} 0.0015937495978413632\n",
    "{'lr': 0.004531902539657156, 'wd': 0, 'batch_size': 8, 'layer_size': 256} 0.0005863353168515718 w/o bandpass, 10\n",
    "{'lr': 0.0017668188704620857, 'wd': 0, 'batch_size': 8, 'layer_size': 256} 0.0009116247971238728 bandpass, 10\n",
    "{'lr': 0.006820280279552952, 'wd': 0, 'batch_size': 8, 'layer_size': 256} 0.0004986349987892337 with 2x stride 2\n",
    "{'lr': 0.007810417589096403, 'wd': 0, 'batch_size': 8, 'layer_size': 256} 0.0004332348386333898 with 1x stride 2\n",
    "{'lr': 0.0015365439418637585, 'wd': 0, 'batch_size': 8, 'layer_size': 128} 0.0007714835297364866\n",
    "{'lr': 0.02716233959851866, 'wd': 0, 'batch_size': 32, 'layer_size': 128} 0.0013283919510080145\n",
    "{'lr': 0.0019890548242081614, 'wd': 0, 'batch_size': 16, 'layer_size': 128} 0.00144807931687008\n",
    "{'lr': 0.0038625945811403732, 'wd': 0, 'batch_size': 16, 'layer_size': 128} 0.0013378030157384826\n",
    "{'lr': 0.0017112891648358517, 'wd': 0, 'batch_size': 32, 'layer_size': 128} 0.0019708356504062456\n",
    "{'lr': 0.0029673206198941445, 'wd': 0, 'batch_size': 8, 'layer_size': 128} 0.0008134577474093409\n",
    "{'lr': 0.00032813453637735567, 'wd': 0, 'batch_size': 64, 'layer_size': 128} 0.0008\n",
    "{'lr': 0.0011704653180570925, 'wd': 0, 'batch_size': 8, 'layer_size': 128} 0.0010375047129388723\n",
    "{'lr': 0.0025766834278764987, 'wd': 0, 'batch_size': 16, 'layer_size': 128} 0.0018318614236014928"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "354f4492",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 / 128, train loss = 0.1964689214, val loss = 0.1886799426\n",
      "\tval loss decreased from inf to 0.1886799426\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mempty_cache()\n\u001b[1;32m      3\u001b[0m \u001b[39m# train({'lr': 0.01, 'wd': 0, 'batch_size': 8, 'layer_size': 256}, train_dataset, 1)\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m train({\u001b[39m'\u001b[39;49m\u001b[39mlr\u001b[39;49m\u001b[39m'\u001b[39;49m: \u001b[39m0.01\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mwd\u001b[39;49m\u001b[39m'\u001b[39;49m: \u001b[39m0\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mbatch_size\u001b[39;49m\u001b[39m'\u001b[39;49m: \u001b[39m8\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mlayer_size\u001b[39;49m\u001b[39m'\u001b[39;49m: \u001b[39m32\u001b[39;49m}, train_dataset, \u001b[39m2\u001b[39;49m) \u001b[39m# scg: 0.0015, ecg: 0.005\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[12], line 59\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(config, train_dataset, model_num, is_tune, data_id, data_dir)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[39m# Calculate training loss and do backpropagation\u001b[39;00m\n\u001b[1;32m     58\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m---> 59\u001b[0m output \u001b[39m=\u001b[39m model(inputs)\n\u001b[1;32m     60\u001b[0m loss \u001b[39m=\u001b[39m criterion(output, lables)\n\u001b[1;32m     61\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/thesis-project-i_Sg-Li3/lib/python3.10/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[8], line 40\u001b[0m, in \u001b[0;36mDeNoise2.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[1;32m     39\u001b[0m     encoded \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencoder(x)\n\u001b[0;32m---> 40\u001b[0m     decoded \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdecoder(encoded)\n\u001b[1;32m     41\u001b[0m     \u001b[39mreturn\u001b[39;00m decoded\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/thesis-project-i_Sg-Li3/lib/python3.10/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/thesis-project-i_Sg-Li3/lib/python3.10/site-packages/torch/nn/modules/container.py:204\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    203\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 204\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    205\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/thesis-project-i_Sg-Li3/lib/python3.10/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/thesis-project-i_Sg-Li3/lib/python3.10/site-packages/torch/nn/modules/batchnorm.py:171\u001b[0m, in \u001b[0;36m_BatchNorm.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    164\u001b[0m     bn_training \u001b[39m=\u001b[39m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrunning_mean \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m) \u001b[39mand\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrunning_var \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    166\u001b[0m \u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    167\u001b[0m \u001b[39mBuffers are only updated if they are to be tracked and we are in training mode. Thus they only need to be\u001b[39;00m\n\u001b[1;32m    168\u001b[0m \u001b[39mpassed when the update should occur (i.e. in training mode when they are tracked), or when buffer stats are\u001b[39;00m\n\u001b[1;32m    169\u001b[0m \u001b[39mused for normalization (i.e. in eval mode when buffers are not None).\u001b[39;00m\n\u001b[1;32m    170\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 171\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mbatch_norm(\n\u001b[1;32m    172\u001b[0m     \u001b[39minput\u001b[39;49m,\n\u001b[1;32m    173\u001b[0m     \u001b[39m# If buffers are not to be tracked, ensure that they won't be updated\u001b[39;49;00m\n\u001b[1;32m    174\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrunning_mean\n\u001b[1;32m    175\u001b[0m     \u001b[39mif\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining \u001b[39mor\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrack_running_stats\n\u001b[1;32m    176\u001b[0m     \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    177\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrunning_var \u001b[39mif\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining \u001b[39mor\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrack_running_stats \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    178\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight,\n\u001b[1;32m    179\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias,\n\u001b[1;32m    180\u001b[0m     bn_training,\n\u001b[1;32m    181\u001b[0m     exponential_average_factor,\n\u001b[1;32m    182\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49meps,\n\u001b[1;32m    183\u001b[0m )\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/thesis-project-i_Sg-Li3/lib/python3.10/site-packages/torch/nn/functional.py:2450\u001b[0m, in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   2447\u001b[0m \u001b[39mif\u001b[39;00m training:\n\u001b[1;32m   2448\u001b[0m     _verify_batch_size(\u001b[39minput\u001b[39m\u001b[39m.\u001b[39msize())\n\u001b[0;32m-> 2450\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49mbatch_norm(\n\u001b[1;32m   2451\u001b[0m     \u001b[39minput\u001b[39;49m, weight, bias, running_mean, running_var, training, momentum, eps, torch\u001b[39m.\u001b[39;49mbackends\u001b[39m.\u001b[39;49mcudnn\u001b[39m.\u001b[39;49menabled\n\u001b[1;32m   2452\u001b[0m )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "\n",
    "# train({'lr': 0.01, 'wd': 0, 'batch_size': 8, 'layer_size': 256}, train_dataset, 1)\n",
    "train({'lr': 0.01, 'wd': 0, 'batch_size': 8, 'layer_size': 32}, train_dataset, 2) # scg: 0.0015, ecg: 0.005"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "550d9c55",
   "metadata": {},
   "source": [
    "## Hyperparametertuning\n",
    "\n",
    "The following code cell implements the hyperparametertuning. It was modeled after a [tutorial](https://pytorch.org/tutorials/beginner/hyperparameter_tuning_tutorial.html) by PyTorch, using RayTune as a tool for hyperparameter tuning. For optimizing the hyperparameters, the `ASHAScheduler` is being used and the loss should be minimized. The configuration defines the hyperparameters to be optimized. Here only the learning rate `lr`, the batch size `batch_size` and the layer size `layer_size` of the models will be taken into consideration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd2406ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Method used for hyperparameter tuning of the machine learning models with a given config. \n",
    "\n",
    ":param dataset: The train dataset.\n",
    ":param config: The configuration for hyperparameter tuning as a dict. Includes the following parameters: \n",
    "                    - the learning rate (lr, float)\n",
    "                    - weight decay (wd, float)\n",
    "                    - batch size (batch_size, int)\n",
    "                    - layer size (layer_size, int)\n",
    ":param num_samples: The number different configurations of the parameters in the config that will be tested.\n",
    ":param max_num_epochs: The number of epochs that will be used for each sample when training.\n",
    ":param model_num: The number of the autoencoder (1 or 2).\n",
    "'''\n",
    "def hypertuning(dataset, config, num_samples, max_num_epochs, model_num):\n",
    "\n",
    "    ray.init()\n",
    "    \n",
    "    # As a scheduler, the ASHAScheduler is being used with the task to minimize the loss.\n",
    "    scheduler = ASHAScheduler(metric='loss', mode='min', max_t=max_num_epochs, grace_period=4, reduction_factor=2)\n",
    "    # Reports the results to the console.\n",
    "    reporter = CLIReporter(metric_columns=['loss', 'training_iteration'])\n",
    "    # To put the dataset to the ray object store for faster and more efficient access.\n",
    "    data_id = put(dataset)\n",
    "    # Runs the scheduler with the train method. \n",
    "    result = tune.run(\n",
    "        partial(train, train_dataset=None, model_num=model_num, is_tune=True, data_id=data_id, data_dir=None),\n",
    "        resources_per_trial={'cpu': 8, 'gpu': 1},\n",
    "        config=config,\n",
    "        num_samples=num_samples,\n",
    "        scheduler=scheduler,\n",
    "        progress_reporter=reporter\n",
    "    )\n",
    "\n",
    "    best_trial = result.get_best_trial('loss', 'min', 'last')\n",
    "    print(\"Best trial config: {}\".format(best_trial.config))\n",
    "    print(\"Best trial final validation loss: {}\".format(best_trial.last_result[\"loss\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cfe8d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'lr': tune.loguniform(1e-4, 1e-1),\n",
    "    'wd': 0,\n",
    "    'batch_size': tune.choice([8]),\n",
    "    'layer_size': tune.choice([256])\n",
    "}\n",
    "\n",
    "# hypertuning(train_dataset, config, num_samples=16, max_num_epochs=32, model_num=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21410168",
   "metadata": {},
   "source": [
    "## Testing and Evaluation\n",
    "\n",
    "The following code cells implement the testing and evaluation behaviour. The first cell defines several evaluation metrics that will be used in the subsequent functions. Thereafter, some utility functions to plot and save the results are implemented. The main function, however, forms the test function which implements the whole testing and evaluation procedure. The function will be called with a configuration, the contents of which will be descibed later. This config descibes which models should be evaluated and determines some parameters for later plotting and presentation of the results. The test function tests all models against all evaluation metrics an all `test_target_snr_dbs` with the test dataset and saves the results a results dictionairy. I.e. the dict has the following structure: results[method][scope][evaluation_method]. The method can either be 'AE1' or 'AE2' for the autoencoder models and 'WD' for Wavelet Denoising, while the scope can be either value from `test_target_snr_dbs` or `all` for a collection of values over all SNR values. The name of the evaluation method coincides with the function names of the first cell. For the CPU time, only the prediction tasl will be measured and any preprocessing or postprocessing tasks like reshaping the input tensors will be neglected. For this, the `process_time()` will be used which returns the sum of the system and user CPU time of the current process [Doc](https://docs.python.org/3/library/time.html#time.process_time). Lastly, the noise model for testing will be added to the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d3bbad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here, some evaluation metrics are implemented.\n",
    "\n",
    "# Mean-Squared Error\n",
    "def mse(signal_clean, signal_noisy):\n",
    "    return mean_squared_error(signal_clean, signal_noisy)\n",
    "\n",
    "# Mean-Absolute Error\n",
    "def mae(signal_clean, signal_noisy):\n",
    "    return mean_absolute_error(signal_clean, signal_noisy)\n",
    "\n",
    "# Root Mean-Squared Error\n",
    "def rmse(signal_clean, signal_noisy):\n",
    "    return np.sqrt(mse(signal_clean, signal_noisy))\n",
    "\n",
    "# Signal-to-noise ratio\n",
    "def snr(signal_clean, signal_noisy):\n",
    "    return 10 * np.log10(np.sum(signal_clean ** 2) / (np.sum((signal_noisy - signal_clean) ** 2)))\n",
    "\n",
    "# Peak signal-to-noise ratio\n",
    "def psnr(signal_clean, signal_noisy):\n",
    "    max_clean = np.max(signal_clean)\n",
    "    rmse_val = rmse(signal_clean, signal_noisy)\n",
    "    return 20 * np.log10(max_clean / rmse_val)\n",
    "\n",
    "# Root mean squared difference\n",
    "def prd(signal_clean, signal_noisy):\n",
    "    return np.sqrt(np.sum((signal_clean - signal_noisy) ** 2) / np.sum(signal_clean ** 2)) * 100\n",
    "\n",
    "# Cross-Correlation\n",
    "def xcorr(signal_clean, signal_noisy):\n",
    "    return np.mean(ccf(signal_clean, signal_noisy, adjusted=False))\n",
    "\n",
    "# Pearson Correlation Coefficient\n",
    "def pcorr(signal_clean, signal_noisy):\n",
    "    return np.corrcoef(signal_clean, signal_noisy)[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd42bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Utility function to plot a bar chart.\n",
    "\n",
    ":param name_short: The short name of the evaluation method.\n",
    ":param results: The results dict that was returned from the test method.\n",
    ":param labels: The labels for the bar charts on the y-axis.\n",
    ":param target_snr_print: The SNR values that will be printed. Has to be a subset of test_target_snr_dbs\n",
    ":param xlabel: The label on the x-axis.\n",
    ":param ylabel: The label on the y-axis.\n",
    ":param title: The title of the chart.\n",
    ":param directory: The directory in which the chart should be saved as a png.\n",
    "'''\n",
    "def plot_result_bar(name_short, results, labels, target_snr_print, xlabel, ylabel, title, directory):\n",
    "    data = [[np.mean(results[method][scope][name_short]) for method in results.keys()] for scope in target_snr_print + ['all']]\n",
    "    plt.xticks(range(len(data[0])), labels)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.title(title)\n",
    "    width = 0.12\n",
    "\n",
    "    for i in range(len(target_snr_print) + 1):\n",
    "        plt.bar(np.arange(len(data[i])) + i * width, data[i], width=width)\n",
    "    plt.legend(target_snr_print + ['all'])\n",
    "    \n",
    "    plt.savefig(os.path.join(directory, name_short + '.png'), format='png')\n",
    "    plt.show()\n",
    "\n",
    "'''\n",
    "Utility function to save the results dict that was returned from the test method as a json and to plot the results. \n",
    "\n",
    ":param directory: The directory to which the results should be saved.\n",
    ":param results: The results dict that was returned from the test method.\n",
    ":param config: The config dict from the test method.\n",
    "'''\n",
    "def save_results(directory, results, config):\n",
    "\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "\n",
    "    results_print = {method: {scope: {evaluation: {'mean': float(np.mean(values)), 'sd': float(np.std(values))} for evaluation, values in eval_method.items()} for scope, eval_method in method_value.items()} for method, method_value in results.items()}\n",
    "    with open(os.path.join(directory, 'results.json'), 'w+') as output_file:\n",
    "        json.dump(results_print, output_file, indent=4)\n",
    "\n",
    "    plot_result_bar('snr_imp', results, config['labels'], config['target_snr_print'], config['xlabel'], 'SNR Improvement (dB)', 'Mean SNR Improvement', directory)\n",
    "    plot_result_bar('mse', results, config['labels'], config['target_snr_print'], config['xlabel'], 'MSE', 'Mean MSE', directory)\n",
    "    plot_result_bar('rmse', results, config['labels'], config['target_snr_print'], config['xlabel'], 'RMSE', 'Mean RMSE', directory)\n",
    "    plot_result_bar('mae', results, config['labels'], config['target_snr_print'], config['xlabel'], 'MAE', 'Mean MAE', directory)\n",
    "    plot_result_bar('psnr', results, config['labels'], config['target_snr_print'], config['xlabel'], 'PSNR', 'Mean PSNR', directory)\n",
    "    plot_result_bar('xcorr', results, config['labels'], config['target_snr_print'], config['xlabel'], 'Cross Correlation', 'Mean Cross Correlation', directory)\n",
    "    plot_result_bar('pcorr', results, config['labels'], config['target_snr_print'], config['xlabel'], 'Pearson Correlation Coefficient', 'Mean Pearson Correlation Coefficient', directory)\n",
    "    plot_result_bar('prd', results, config['labels'], config['target_snr_print'], config['xlabel'], 'PRD (%)', 'Mean PRD', directory)\n",
    "\n",
    "    # CPU Consumption\n",
    "    data = [np.mean(results[method]['all']['cpu_time']) * 1000 for method in results.keys()]\n",
    "\n",
    "    plt.xticks(range(len(data)), config['labels'])\n",
    "    plt.xlabel('Denoising Method')\n",
    "    plt.ylabel('CPU Time (ms)')\n",
    "    plt.title('Mean CPU Time')\n",
    "\n",
    "    plt.bar(np.arange(len(data)), data)\n",
    "    \n",
    "    plt.savefig(os.path.join(directory, 'cpu.png'))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab33828",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Method used for testing the denoising methods with regards to a specific config. \n",
    "\n",
    ":param config: The configuration for hyperparameter tuning as a dict. Includes the following parameters: \n",
    "                    - methods           (list of strings):  The used method from 'AE1', 'AE2' or 'WD' for the first or second autoencoder or the noise wavelet denoising\n",
    "                    - models            (list of strings):  The path to the saved model which matches the corresponding method on the same location in the list\n",
    "                    - labels            (list of strings):  The labels for the different methods in the diagrams\n",
    "                    - target_snr_print  (list of ints):     The SNR that should be printed in the diagrams\n",
    "                    - bandpass          (bool):             True, if a bandpass filter should be applied to the results, False otherwise\n",
    "                    - ecg               (bool):             If set to True, the implications of the denoising model on the transformation of scg to ecg will be tested\n",
    "                    - ecg_model         (string):           The path to the transformation model of the ecg,\n",
    "                    - xlabel            (string):           The label for the x-axis in the diagram\n",
    "'''\n",
    "def test(config):\n",
    "    \n",
    "    with torch.no_grad():\n",
    "\n",
    "        # A dict to save the resuls in\n",
    "        results = {}\n",
    "\n",
    "        if config['ecg']:\n",
    "            # Loads the model for the transformation of scg to ecg\n",
    "            model_ecg = DeNoise2(layer_size=128).to(device)\n",
    "            model_ecg.load_state_dict(torch.load(os.path.join(model_directory, config['ecg_model']), map_location=torch.device(device)))\n",
    "            model_ecg.eval()\n",
    "\n",
    "        for i, method in enumerate(config['methods']):\n",
    "\n",
    "            label = config['labels'][i]\n",
    "\n",
    "            # initializes the current machine learning models\n",
    "            if method == 'AE1':\n",
    "                model = DeNoise1(layer_size=256).to(device)\n",
    "                model.load_state_dict(torch.load(os.path.join(model_directory, config['models'][i]), map_location=torch.device(device)))\n",
    "                model.eval()\n",
    "            elif method in ['AE2', 'ECG']:\n",
    "                model = DeNoise2(layer_size=128).to(device)\n",
    "                model.load_state_dict(torch.load(os.path.join(model_directory, config['models'][i]), map_location=torch.device(device)))\n",
    "                model.eval()\n",
    "\n",
    "            # initialize the dict for the different parameters to be tested\n",
    "            results[label] = {}\n",
    "            for target in test_target_snr_dbs + ['all', 'ecg_noise', 'ecg_pred']:\n",
    "                results[label][target] = {\n",
    "                    'result': [],\n",
    "                    'snr_imp': [],\n",
    "                    'mse': [],\n",
    "                    'rmse': [],\n",
    "                    'mae': [],\n",
    "                    'psnr': [],\n",
    "                    'xcorr': [],\n",
    "                    'pcorr': [],\n",
    "                    'prd': [],\n",
    "                    'cpu_time': []\n",
    "                }\n",
    "            \n",
    "            i = 0\n",
    "            # Calculate the results for each sample in the test dataset\n",
    "            for i, (noise, clean) in enumerate(test_dataset):\n",
    "                \n",
    "                cpu_time = 0\n",
    "\n",
    "                # test the corresponding method\n",
    "                if method in ['AE1', 'AE2', 'ECG']:\n",
    "                    noise = noise.reshape(-1, 1, window_size).to(device, dtype=torch.float)\n",
    "\n",
    "                    # record the cpu time as the process time\n",
    "                    cpu_time_start = time.process_time()\n",
    "                    predicted = model(noise)\n",
    "                    cpu_time_stop = time.process_time()\n",
    "                    cpu_time = cpu_time_stop - cpu_time_start\n",
    "\n",
    "                    noise = noise.to('cpu').reshape(window_size).numpy()\n",
    "                    predicted = predicted.to('cpu').reshape(window_size).numpy()\n",
    "                elif method == 'WD':\n",
    "                    noise = noise.numpy()\n",
    "\n",
    "                    # record the cpu time as the process time\n",
    "                    cpu_time_start = time.process_time()\n",
    "                    predicted = denoise_wavelet(noise, method='BayesShrink', mode='soft', wavelet_levels=1, wavelet='sym8', rescale_sigma='True')\n",
    "                    cpu_time_stop = time.process_time()\n",
    "                    cpu_time = cpu_time_stop - cpu_time_start\n",
    "                    predicted = denormalize(predicted, test_dataset.dataset.min_val, test_dataset.dataset.max_val)\n",
    "\n",
    "                clean = clean.numpy()\n",
    "\n",
    "                if config['bandpass']:\n",
    "                    predicted = bandpass(predicted)\n",
    "\n",
    "                if config['ecg']:\n",
    "\n",
    "                    predicted = torch.from_numpy(predicted).reshape(-1, 1, window_size).to(device, dtype=torch.float)\n",
    "                    noise = torch.from_numpy(noise).reshape(-1, 1, window_size).to(device, dtype=torch.float)\n",
    "                    \n",
    "                    # get the transformed signal from the noisy and predicted/denoisied scg signal\n",
    "                    predicted_ecg_noise = model(noise)\n",
    "                    predicted_ecg_pred = model(predicted)\n",
    "\n",
    "                    results[label]['ecg_noise']['rmse'].append([rmse(clean, predicted_ecg_noise)])\n",
    "                    results[label]['ecg_noise']['pcorr'].append([pcorr(clean, predicted_ecg_noise)]) \n",
    "\n",
    "                    results[label]['ecg_pred']['rmse'].append([rmse(clean, predicted_ecg_pred)])\n",
    "                    results[label]['ecg_pred']['pcorr'].append([pcorr(clean, predicted_ecg_pred)]) \n",
    "                \n",
    "                else:\n",
    "                    # Denormalize the predicted and noise values for the calculation of the SNR as it depends on absolute values.\n",
    "                    noise_snr = noise if method == 'ECG' else denormalize(noise, test_dataset.dataset.min_val, test_dataset.dataset.max_val)\n",
    "                    \n",
    "                    # calculate the performance measures for each SNR on the test dataset.\n",
    "                    snr_data = snr(clean, noise_snr)\n",
    "                    for target in test_target_snr_dbs + ['all']:\n",
    "                        if (str(target) == 'all') or (snr_data > (target - 0.8) and snr_data < (target + 0.8)):\n",
    "                            i += 1\n",
    "                            results[label][target]['result'].append(predicted)\n",
    "                            results[label][target]['snr_imp'].append([snr(clean, predicted) - snr_data])\n",
    "                            results[label][target]['mse'].append([mse(clean, predicted)])\n",
    "                            results[label][target]['rmse'].append([rmse(clean, predicted)])\n",
    "                            results[label][target]['mae'].append([mae(clean, predicted)])\n",
    "                            # results[label][target]['psnr'].append([psnr(clean, predicted)])\n",
    "                            results[label][target]['xcorr'].append([xcorr(clean, predicted)])\n",
    "                            results[label][target]['pcorr'].append([pcorr(clean, predicted)])\n",
    "                            results[label][target]['prd'].append([prd(clean, predicted)])\n",
    "                            results[label][target]['cpu_time'].append(cpu_time)\n",
    "            \n",
    "            print(i)\n",
    "            value = 'all'\n",
    "            print('*** ' + label + ' ***')\n",
    "            print(len(results[label][value]['result']))\n",
    "            print('SNR IMP ' + str(np.mean(results[label][value]['snr_imp'])))\n",
    "            print('RMSE ' + str(np.mean(results[label][value]['rmse'])))\n",
    "            print('PCORR ' + str(np.mean(results[label][value]['pcorr'])))\n",
    "            print('CPU TIME ' + str(np.mean(results[label][value]['cpu_time'])))\n",
    "            print()\n",
    "\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3266b49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing is done with a different set of target signal-to-noise ratios. Those are set here.\n",
    "test_dataset.dataset.add_noise(test_target_snr_dbs, noise_model='WGN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fbe20c1",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 57\u001b[0m\n\u001b[1;32m     35\u001b[0m config3_1 \u001b[39m=\u001b[39m {\n\u001b[1;32m     36\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mmethods\u001b[39m\u001b[39m'\u001b[39m: [\u001b[39m'\u001b[39m\u001b[39mECG\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[1;32m     37\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mmodels\u001b[39m\u001b[39m'\u001b[39m: [\u001b[39m'\u001b[39m\u001b[39mmodel_2.pth\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mxlabel\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39mDenoising Method\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m     44\u001b[0m }\n\u001b[1;32m     46\u001b[0m config3 \u001b[39m=\u001b[39m {\n\u001b[1;32m     47\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mmethods\u001b[39m\u001b[39m'\u001b[39m: [\u001b[39m'\u001b[39m\u001b[39mAE1\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mAE2\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mWD\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[1;32m     48\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mmodels\u001b[39m\u001b[39m'\u001b[39m: [\u001b[39m'\u001b[39m\u001b[39mmodel_1.pth\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mmodel_1\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mold/normal_full/model_2_1024_relu_extended_10.pth\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mold/normal_full/model_2_1024_relu_extended_20.pth\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mxlabel\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39mDenoising Method\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m     55\u001b[0m }\n\u001b[0;32m---> 57\u001b[0m results \u001b[39m=\u001b[39m test(config3_1)\n\u001b[1;32m     58\u001b[0m \u001b[39m# save_results('./results/2/', results, config3_1)\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[17], line 112\u001b[0m, in \u001b[0;36mtest\u001b[0;34m(config)\u001b[0m\n\u001b[1;32m    110\u001b[0m results[label][target][\u001b[39m'\u001b[39m\u001b[39mresult\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mappend(predicted)\n\u001b[1;32m    111\u001b[0m results[label][target][\u001b[39m'\u001b[39m\u001b[39msnr_imp\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mappend([snr(clean, predicted) \u001b[39m-\u001b[39m snr_data])\n\u001b[0;32m--> 112\u001b[0m results[label][target][\u001b[39m'\u001b[39m\u001b[39mmse\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mappend([mse(clean, predicted)])\n\u001b[1;32m    113\u001b[0m results[label][target][\u001b[39m'\u001b[39m\u001b[39mrmse\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mappend([rmse(clean, predicted)])\n\u001b[1;32m    114\u001b[0m results[label][target][\u001b[39m'\u001b[39m\u001b[39mmae\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mappend([mae(clean, predicted)])\n",
      "Cell \u001b[0;32mIn[15], line 5\u001b[0m, in \u001b[0;36mmse\u001b[0;34m(signal_clean, signal_noisy)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmse\u001b[39m(signal_clean, signal_noisy):\n\u001b[0;32m----> 5\u001b[0m     \u001b[39mreturn\u001b[39;00m mean_squared_error(signal_clean, signal_noisy)\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/thesis-project-i_Sg-Li3/lib/python3.10/site-packages/sklearn/metrics/_regression.py:442\u001b[0m, in \u001b[0;36mmean_squared_error\u001b[0;34m(y_true, y_pred, sample_weight, multioutput, squared)\u001b[0m\n\u001b[1;32m    382\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmean_squared_error\u001b[39m(\n\u001b[1;32m    383\u001b[0m     y_true, y_pred, \u001b[39m*\u001b[39m, sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, multioutput\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39muniform_average\u001b[39m\u001b[39m\"\u001b[39m, squared\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    384\u001b[0m ):\n\u001b[1;32m    385\u001b[0m     \u001b[39m\"\"\"Mean squared error regression loss.\u001b[39;00m\n\u001b[1;32m    386\u001b[0m \n\u001b[1;32m    387\u001b[0m \u001b[39m    Read more in the :ref:`User Guide <mean_squared_error>`.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    440\u001b[0m \u001b[39m    0.825...\u001b[39;00m\n\u001b[1;32m    441\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 442\u001b[0m     y_type, y_true, y_pred, multioutput \u001b[39m=\u001b[39m _check_reg_targets(\n\u001b[1;32m    443\u001b[0m         y_true, y_pred, multioutput\n\u001b[1;32m    444\u001b[0m     )\n\u001b[1;32m    445\u001b[0m     check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[1;32m    446\u001b[0m     output_errors \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39maverage((y_true \u001b[39m-\u001b[39m y_pred) \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m \u001b[39m2\u001b[39m, axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, weights\u001b[39m=\u001b[39msample_weight)\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/thesis-project-i_Sg-Li3/lib/python3.10/site-packages/sklearn/metrics/_regression.py:102\u001b[0m, in \u001b[0;36m_check_reg_targets\u001b[0;34m(y_true, y_pred, multioutput, dtype)\u001b[0m\n\u001b[1;32m    100\u001b[0m check_consistent_length(y_true, y_pred)\n\u001b[1;32m    101\u001b[0m y_true \u001b[39m=\u001b[39m check_array(y_true, ensure_2d\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, dtype\u001b[39m=\u001b[39mdtype)\n\u001b[0;32m--> 102\u001b[0m y_pred \u001b[39m=\u001b[39m check_array(y_pred, ensure_2d\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, dtype\u001b[39m=\u001b[39;49mdtype)\n\u001b[1;32m    104\u001b[0m \u001b[39mif\u001b[39;00m y_true\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    105\u001b[0m     y_true \u001b[39m=\u001b[39m y_true\u001b[39m.\u001b[39mreshape((\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m))\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/thesis-project-i_Sg-Li3/lib/python3.10/site-packages/sklearn/utils/validation.py:838\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    822\u001b[0m     array \u001b[39m=\u001b[39m _ensure_sparse_format(\n\u001b[1;32m    823\u001b[0m         array,\n\u001b[1;32m    824\u001b[0m         accept_sparse\u001b[39m=\u001b[39maccept_sparse,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    830\u001b[0m         input_name\u001b[39m=\u001b[39minput_name,\n\u001b[1;32m    831\u001b[0m     )\n\u001b[1;32m    832\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    833\u001b[0m     \u001b[39m# If np.array(..) gives ComplexWarning, then we convert the warning\u001b[39;00m\n\u001b[1;32m    834\u001b[0m     \u001b[39m# to an error. This is needed because specifying a non complex\u001b[39;00m\n\u001b[1;32m    835\u001b[0m     \u001b[39m# dtype to the function converts complex to real dtype,\u001b[39;00m\n\u001b[1;32m    836\u001b[0m     \u001b[39m# thereby passing the test made in the lines following the scope\u001b[39;00m\n\u001b[1;32m    837\u001b[0m     \u001b[39m# of warnings context manager.\u001b[39;00m\n\u001b[0;32m--> 838\u001b[0m     \u001b[39mwith\u001b[39;00m warnings\u001b[39m.\u001b[39;49mcatch_warnings():\n\u001b[1;32m    839\u001b[0m         \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    840\u001b[0m             warnings\u001b[39m.\u001b[39msimplefilter(\u001b[39m\"\u001b[39m\u001b[39merror\u001b[39m\u001b[39m\"\u001b[39m, ComplexWarning)\n",
      "File \u001b[0;32m/usr/lib/python3.10/warnings.py:437\u001b[0m, in \u001b[0;36mcatch_warnings.__init__\u001b[0;34m(self, record, module)\u001b[0m\n\u001b[1;32m    420\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mcatch_warnings\u001b[39;00m(\u001b[39mobject\u001b[39m):\n\u001b[1;32m    422\u001b[0m     \u001b[39m\"\"\"A context manager that copies and restores the warnings filter upon\u001b[39;00m\n\u001b[1;32m    423\u001b[0m \u001b[39m    exiting the context.\u001b[39;00m\n\u001b[1;32m    424\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    434\u001b[0m \n\u001b[1;32m    435\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 437\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39m, record\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, module\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    438\u001b[0m         \u001b[39m\"\"\"Specify whether to record warnings and if an alternative module\u001b[39;00m\n\u001b[1;32m    439\u001b[0m \u001b[39m        should be used other than sys.modules['warnings'].\u001b[39;00m\n\u001b[1;32m    440\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    443\u001b[0m \n\u001b[1;32m    444\u001b[0m \u001b[39m        \"\"\"\u001b[39;00m\n\u001b[1;32m    445\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_record \u001b[39m=\u001b[39m record\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# The config describes, which parameters should be tested.\n",
    "config0 = {\n",
    "    'methods': ['AE2', 'AE2', 'AE2', 'AE2'], #, 'WD']\n",
    "    'models': ['model_2.pth', 'new/normal/m2_128_10.pth', 'new/normal/m2_128_20.pth', 'new/normal/m2_128_50.pth'],\n",
    "    'labels': ['Training Data', 'Results', 'Training Data + Results', 'No Usage'],\n",
    "    'target_snr_print': [-1, 0, 1, 3, 8], # [-1, 0, 0.5, 1, 3, 5, 8]\n",
    "    'bandpass': False,\n",
    "    'ecg': False,\n",
    "    'ecg_model': None,\n",
    "    'xlabel': 'Bandpass Filter Usage'\n",
    "}\n",
    "\n",
    "config1 = {\n",
    "    'methods': ['AE2', 'AE2', 'AE2', 'AE2'], #, 'WD']\n",
    "    'models': ['new/normal/m2_128_simple.pth', 'new/normal/m2_128_10.pth', 'new/normal/m2_128_20.pth', 'new/normal/m2_128_50.pth'],\n",
    "    'labels': ['1', '2', '3', '4'],\n",
    "    'target_snr_print': [-5, -1, 0, 3, 6, 9], # [-5, -1, 0, 3, 6, 9]\n",
    "    'bandpass': False,\n",
    "    'ecg': False,\n",
    "    'ecg_model': None,\n",
    "    'xlabel': 'Noise Distribution'\n",
    "}\n",
    "\n",
    "config2 = {\n",
    "    'methods': ['AE2', 'WD'],\n",
    "    'models': ['model_2.pth', 'new/normal/m2_128_20.pth'],\n",
    "    'labels': ['AE2', 'WD'],\n",
    "    'target_snr_print': [-1, 0, 2, 5, 7], # [-1, 0, 2, 5, 7]\n",
    "    'bandpass': False,\n",
    "    'ecg': False,\n",
    "    'ecg_model': None,\n",
    "    'xlabel': 'Denoising Method'\n",
    "}\n",
    "\n",
    "config3_1 = {\n",
    "    'methods': ['ECG'],\n",
    "    'models': ['model_2.pth'],\n",
    "    'labels': ['AE2'],\n",
    "    'target_snr_print': [], # [-1, 0, 2, 5, 7]\n",
    "    'bandpass': False,\n",
    "    'ecg': False,\n",
    "    'ecg_model': None,\n",
    "    'xlabel': 'Denoising Method'\n",
    "}\n",
    "\n",
    "config3_2 = {\n",
    "    'methods': ['AE1', 'AE2', 'WD'],\n",
    "    'models': ['model_1.pth', 'model_1', 'old/normal_full/model_2_1024_relu_extended_10.pth', 'old/normal_full/model_2_1024_relu_extended_20.pth'],\n",
    "    'labels': ['AE1', 'AE2', 'WD'],\n",
    "    'target_snr_print': [-1, 0, 1, 3, 8], # [-1, 0, 0.5, 1, 3, 5, 8]\n",
    "    'bandpass': False,\n",
    "    'ecg': True,\n",
    "    'ecg_model': 'ecg/model_2.pth',\n",
    "    'xlabel': 'Denoising Method'\n",
    "}\n",
    "\n",
    "results = test(config3_1)\n",
    "# save_results('./results/2/', results, config3_1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f6c2eda4",
   "metadata": {},
   "source": [
    "## Utility Functions for Evaluation and Visualization\n",
    "\n",
    "The following cells include code to generate visualizations or to extract important numbers for the bachelor's thesis. This includes visualizations of the denoising performance and the noise model and measures to compare the different denoising methods against each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10269bec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# VISUALIZATIONS FOR THE LEARNING BEHAVIOUR\n",
    "\n",
    "# Visualizes the the validation and train loss of the given loss.csv in one graph\n",
    "\n",
    "filename = 'models/new/bandpass/loss_2.csv'\n",
    "\n",
    "df = pd.read_csv(filename)\n",
    "\n",
    "plt.plot(df['epoch'], df['val_loss'], color='#087ffb', label='validation loss')\n",
    "plt.plot(df['epoch'], df['train_loss'], color='#ea002e', label='train loss')\n",
    "\n",
    "plt.title('Validation and Train Loss of AE1')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc3d34b9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'DeNoise2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 8\u001b[0m\n\u001b[1;32m      3\u001b[0m ecg \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[39m# model = DeNoise1(layer_size=256).to(device)\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[39m# model.load_state_dict(torch.load(os.path.join(model_directory, 'new/wgn/m2_128_20.pth'), map_location=torch.device(device)))\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m model \u001b[39m=\u001b[39m DeNoise2(layer_size\u001b[39m=\u001b[39m\u001b[39m128\u001b[39m)\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m      9\u001b[0m model\u001b[39m.\u001b[39mload_state_dict(torch\u001b[39m.\u001b[39mload(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(model_directory, \u001b[39m'\u001b[39m\u001b[39mmodel_2.pth\u001b[39m\u001b[39m'\u001b[39m), map_location\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mdevice(device)))\n\u001b[1;32m     11\u001b[0m model_ecg \u001b[39m=\u001b[39m DeNoise2(layer_size\u001b[39m=\u001b[39m\u001b[39m128\u001b[39m)\u001b[39m.\u001b[39mto(device)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'DeNoise2' is not defined"
     ]
    }
   ],
   "source": [
    "# VISUALIZATIONS FOR THE DENOISING PERFORMANCE AND THE NOSIE MODEL\n",
    "\n",
    "# Visualizes clean and noisy signal in one graph and the clean and denoised signal in another. \n",
    "# The signal will be selected randomly and the denoising method can be configured. What is more, the \n",
    "# implications of the used method on the transformation of scg to ecg can be visualized.\n",
    "\n",
    "ecg = True\n",
    "\n",
    "# model = DeNoise1(layer_size=256).to(device)\n",
    "# model.load_state_dict(torch.load(os.path.join(model_directory, 'new/wgn/m2_128_20.pth'), map_location=torch.device(device)))\n",
    "\n",
    "model = DeNoise2(layer_size=128).to(device)\n",
    "model.load_state_dict(torch.load(os.path.join(model_directory, 'model_2.pth'), map_location=torch.device(device)))\n",
    "\n",
    "model_ecg = DeNoise2(layer_size=128).to(device)\n",
    "model_ecg.load_state_dict(torch.load(os.path.join(model_directory, 'new/bandpass/model_2.pth'), map_location=torch.device(device)))\n",
    "\n",
    "model.eval()\n",
    "model_ecg.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    \n",
    "    i = random.choice(range(0, len(test_dataset)))\n",
    "    print(f'Sample index: {i}')\n",
    "\n",
    "    noise, clean = test_dataset[i]\n",
    "\n",
    "    clean, noise = clean.reshape(-1, 1, window_size).to(device, dtype=torch.float), noise.reshape(-1, 1, window_size).to(device, dtype=torch.float)\n",
    "\n",
    "    predicted = model(noise)\n",
    "    # predicted = denoise_wavelet(noise, method='BayesShrink', mode='soft', wavelet_levels=1, wavelet='sym8', rescale_sigma='True')\n",
    "    predicted_ecg = model_ecg(predicted)\n",
    "\n",
    "    predicted = predicted.to('cpu').reshape(window_size).numpy()\n",
    "    predicted_ecg = predicted_ecg.to('cpu').reshape(window_size).numpy()\n",
    "    clean = clean.to('cpu').reshape(window_size).numpy()\n",
    "    noise = noise.to('cpu').reshape(window_size).numpy()\n",
    "\n",
    "    noise_snr = noise if ecg else denormalize(noise, test_dataset.dataset.min_val, test_dataset.dataset.max_val)\n",
    "    predicted = predicted_ecg if ecg else predicted\n",
    "\n",
    "    print(f'RMSE \\nClean/Noise: {rmse(clean, noise)}\\nClean/Predicted: {rmse(clean, predicted)}\\n\\n')\n",
    "    print(f'SNR \\nClean/Noise: {snr(clean, noise_snr)}\\nClean/Predicted: {snr(clean, predicted)}\\nClean/BP: {snr(clean, bandpass(predicted))}\\n\\n')\n",
    "    print(f'PCORR \\nClean/Noise: {pcorr(clean, noise)}\\nClean/Predicted: {pcorr(clean, predicted)}\\nClean/BP: {pcorr(clean, bandpass(predicted))}\\n\\n')\n",
    "    \n",
    "    time_from = 0\n",
    "    time_to = 512\n",
    "\n",
    "\n",
    "    # Clean/Noise Graph\n",
    "    plt.figure(figsize=(14, 4))\n",
    "\n",
    "    x = np.array(range(time_to)[time_from:time_to]) / sampling_rate\n",
    "    plt.plot(x, clean[time_from:time_to], color='#087ffb', label='clean')\n",
    "    plt.plot(x, noise_snr[time_from:time_to], color='#ea002e', label='noise')\n",
    "    plt.xticks(x[::25])\n",
    "    \n",
    "    plt.title('Signal with added noise')\n",
    "    plt.xlabel('Time (s)')\n",
    "    plt.ylabel(r'Acceleration $(\\frac{m}{s^2})$')\n",
    "    plt.ylim(bottom=-1, top=1)\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    # Clean/Denoised Graph\n",
    "    plt.figure(figsize=(14, 4))\n",
    "\n",
    "    x = np.array(range(time_to)[time_from:time_to]) / sampling_rate\n",
    "    plt.plot(x, clean[time_from:time_to], color='#087ffb', label='clean')\n",
    "    plt.plot(x, predicted[time_from:time_to], color='#ea002e', label='denoised')\n",
    "    plt.xticks(x[::25])\n",
    "    \n",
    "    plt.title('Signal that has been denoised with AE2')\n",
    "    plt.xlabel('Time (s)')\n",
    "    plt.ylabel(r'Acceleration $(\\frac{m}{s^2})$')\n",
    "    plt.ylim(bottom=-1, top=1)\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e47b1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparing AE2 with WD\n",
      "\n",
      "Scope: all\n",
      "result: 0.10595, 0.27103: 155.81\n",
      "snr_imp: 9.15619, 0.83984: -90.83\n",
      "mse: 0.03739, 0.05504: 47.23\n",
      "rmse: 0.07090, 0.10479: 47.81\n",
      "mae: 0.07228, 0.08339: 15.37\n",
      "psnr: nan, nan: nan\n",
      "xcorr: 0.00034, 0.00032: -5.48\n",
      "pcorr: 0.30468, 0.29611: -2.81\n",
      "prd: 599.70180, 32.69920: -94.55\n",
      "cpu_time: 0.00649, 0.00126: -80.54\n"
     ]
    }
   ],
   "source": [
    "# COMPARISON OF DIFFERENT DENOISING METHODS\n",
    "\n",
    "# Gives the procentural improvements of the denoted denoising methods (column_1 and column_2)\n",
    "# for specific scopes and a specific metric (mean or sd)\n",
    "\n",
    "filename = 'results/2/results.json'\n",
    "\n",
    "column_1 = 'AE2'\n",
    "column_2 = 'WD'\n",
    "scopes = ['all']\n",
    "metric = 'sd'\n",
    "\n",
    "with open(filename) as json_file:\n",
    "    results = json.load(json_file)\n",
    "\n",
    "    print(f'Comparing {column_1} with {column_2}')\n",
    "    for scope in scopes:\n",
    "        print(f'\\nScope: {scope}')\n",
    "        for evaluation in results[column_1][scope]:\n",
    "            val = results[column_1][scope][evaluation][metric]\n",
    "            val_cmp = results[column_2][scope][evaluation][metric]\n",
    "            \n",
    "            percentage_change = (val_cmp - val) / val * 100\n",
    "            print(f'{evaluation}:\\t{val:.5f},\\t{val_cmp:.5f}:\\t{percentage_change:.2f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis-project-i_Sg-Li3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "e6717f947e3cb42ac9683eac40a7d814e21ca3f0fa83f7d2ca8c93372cd6a329"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
